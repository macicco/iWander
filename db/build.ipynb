{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AstroRV Catalog Ensambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Libraries\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# =============================================================================\n",
    "# Data directories\n",
    "# =============================================================================\n",
    "dir_gaia = \"src/Astro/\"\n",
    "dir_hip = \"src/Astro/\"\n",
    "dir_simbad = \"src/Astro/\"\n",
    "dir_rv = \"src/RV/\"\n",
    "dir_results = \"src/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Load Gaia database\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Gaia-TGAS: \n",
      "Original objects: 2057050 \n",
      "Discarded objects: 30840 \n",
      "Final objects: 2026210\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cols_gaia = [\"source_id\", \"hip\", \"tycho2_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"parallax\", \"parallax_error\", \n",
    "             \"pmra\", \"pmra_error\", \"pmdec\", \"pmdec_error\", \"ra_dec_corr\", \"ra_parallax_corr\", \"ra_pmra_corr\", \n",
    "             \"ra_pmdec_corr\", \"dec_parallax_corr\", \"dec_pmra_corr\", \"dec_pmdec_corr\", \"parallax_pmra_corr\", \n",
    "             \"parallax_pmdec_corr\", \"pmra_pmdec_corr\", \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"phot_g_mean_mag\", \n",
    "             \"l\", \"b\", \"ecl_lon\", \"ecl_lat\"]\n",
    "\n",
    "gaia = pd.DataFrame()\n",
    "for i in range(16):\n",
    "    filename = dir_gaia + \"TgasSource_000-000-0\" + str(i).zfill(2) + \".csv.gz\"\n",
    "    gaia = gaia.append(pd.read_csv(filename, usecols=cols_gaia))\n",
    "\n",
    "gaia.source_id = gaia.source_id.astype(str)\n",
    "gaia.hip = gaia.hip.astype(str)\n",
    "gaia.tycho2_id = gaia.tycho2_id.astype(str)\n",
    "\n",
    "gaia[\"hip\"] = gaia[\"hip\"].map(lambda x: x.replace(\".0\", \"\"))\n",
    "gaia.hip.replace(\"nan\", \"\", inplace=True)\n",
    "gaia.tycho2_id.replace(\"nan\", \"\", regex=True, inplace=True)\n",
    "\n",
    "n1 = len(gaia)\n",
    "gaia = gaia[gaia.parallax > 0]\n",
    "n2 = len(gaia)\n",
    "print(\"\\nDatabase Gaia-TGAS:\", \"\\nOriginal objects:\", n1,\"\\nDiscarded objects:\", n1-n2,\"\\nFinal objects:\", n2)\n",
    "\n",
    "gaia_hip = gaia[gaia.hip != \"\"]\n",
    "gaia_tyc = gaia[gaia.tycho2_id != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Load Hipparcos database\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwander/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Hipparcos: \n",
      "Original objects: 118218 \n",
      "Discarded objects: 263 \n",
      "Final objects: 117955\n"
     ]
    }
   ],
   "source": [
    "# Available in: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.1\n",
    "names_hip={}\n",
    "names_hip[1] = \"hip\"\n",
    "names_hip[8] = \"ra_hip\"\n",
    "names_hip[9] = \"dec_hip\"\n",
    "names_hip[14] = \"ra_error_hip\"\n",
    "names_hip[15] = \"dec_error_hip\"\n",
    "names_hip[19] = \"ra_dec_corr_hip\"\n",
    "names_hip[20] = \"ra_parallax_corr_hip\"\n",
    "names_hip[21] = \"dec_parallax_corr_hip\"\n",
    "names_hip[22] = \"ra_pmra_corr_hip\"\n",
    "names_hip[23] = \"dec_pmra_corr_hip\"\n",
    "names_hip[24] = \"parallax_pmra_corr_hip\"\n",
    "names_hip[25] = \"ra_pmdec_corr_hip\"\n",
    "names_hip[26] = \"dec_pmdec_corr_hip\"\n",
    "names_hip[27] = \"parallax_pmdec_corr_hip\"\n",
    "names_hip[28] = \"pmra_pmdec_corr_hip\"\n",
    "names_hip[5] = \"Vmag_hip\"\n",
    "names_hip[71] = \"HenryDraperId_hip\"\n",
    "#The following columns are not read and left to the improved Hipparcos catalogue:\n",
    "# names_hip[11] = \"parallax_hip\"\n",
    "# names_hip[12] = \"pmra_hip\"\n",
    "# names_hip[13] = \"pmdec_hip\"\n",
    "# names_hip[16] = \"parallax_error_hip\"\n",
    "# names_hip[17] = \"pmra_error_hip\"\n",
    "# names_hip[18] = \"pmdec_error_hip\"\n",
    "#names2_hip[76] = \"sptype_hip\"\n",
    "\n",
    "names_hip = collections.OrderedDict(sorted(names_hip.items()))\n",
    "\n",
    "hipparcos = pd.read_csv(dir_hip + \"hip_main.dat.gz\", delimiter=\"|\", usecols=names_hip.keys(), names=names_hip.values())\n",
    "\n",
    "# Columns format\n",
    "cols = hipparcos.columns.tolist()\n",
    "objects = [\"hip\", \"HenryDraperId_hip\"]\n",
    "cols = [x for x in cols if x not in objects]\n",
    "hipparcos[cols] = hipparcos[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "hipparcos.hip = hipparcos.hip.astype(str)\n",
    "hipparcos.hip = hipparcos.hip.map(lambda x: x.replace(\".0\", \"\"))\n",
    "\n",
    "# Delete null astrometry values\n",
    "n1 = len(hipparcos)\n",
    "hipparcos.dropna(subset=[\"ra_hip\", \"dec_hip\"], how=\"any\", inplace=True)\n",
    "n2 = len(hipparcos)\n",
    "print(\"\\nDatabase Hipparcos:\", \"\\nOriginal objects:\", n1,\"\\nDiscarded objects:\", n1-n2,\"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Load Hipparcos improved\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Hipparcos improved: \n",
      "Original objects: 117955 \n",
      "Discarded objects: 0 \n",
      "Final objects: 117955\n"
     ]
    }
   ],
   "source": [
    "comments=list(range(95))+[96,97]\n",
    "hipvan=pd.read_csv(dir_hip + \"HipVanLeeuwen2007.tsv\",sep=\";\",skiprows=comments)\n",
    "hipvan=hipvan[['_RAJ2000', '_DEJ2000', 'HIP', 'Plx', 'e_Plx', 'pmRA', 'e_pmRA',\n",
    "       'pmDE', 'e_pmDE','Hpmag', 'e_Hpmag', 'B-V', 'e_B-V', 'V-I']]\n",
    "columns={'_RAJ2000':'ra_hip', '_DEJ2000':'dec_hip', 'HIP':'hip', \n",
    "         'Plx':'parallax_hip', 'e_Plx':'parallax_error_hip', \n",
    "         'pmRA':'pmra_hip', 'e_pmRA':'pmra_error_hip',\n",
    "         'pmDE':'pmdec_hip', 'e_pmDE':'pmdec_error_hip','Hpmag':'Hpmag_hip', \n",
    "         'e_Hpmag':'e_Hpmag_hip', 'B-V':'B_V_hip', 'e_B-V':'e_B_V_hip',\n",
    "         'V-I':'V_I_hip'}\n",
    "hipvan.rename(columns=columns,inplace=True)\n",
    "\n",
    "cols = hipvan.columns.tolist()\n",
    "objects = [\"hip\"]\n",
    "cols = [x for x in cols if x not in objects]\n",
    "hipvan[cols] = hipvan[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "hipvan.hip = hipvan.hip.astype(str)\n",
    "hipvan.hip = hipvan.hip.map(lambda x: x.replace(\".0\", \"\"))\n",
    "\n",
    "# Delete null astrometry values\n",
    "n1 = len(hipvan)\n",
    "hipvan.dropna(subset=[\"ra_hip\", \"dec_hip\", \"parallax_hip\"], how=\"any\", inplace=True)\n",
    "n2 = len(hipvan)\n",
    "print(\"\\nDatabase Hipparcos improved:\", \"\\nOriginal objects:\", n1,\"\\nDiscarded objects:\", n1-n2,\"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Hipparcos + HipVanLeeuwen2007\n",
    "cols = ['hip', 'parallax_hip', 'pmra_hip', 'pmdec_hip', 'parallax_error_hip', 'pmra_error_hip','pmdec_error_hip']\n",
    "hipparcos = hipparcos.merge(hipvan[cols], on='hip', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Load Tycho database\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Tycho: \n",
      "Original objects: 1058332 \n",
      "Discarded objects: 22887 \n",
      "Final objects: 1035445\n"
     ]
    }
   ],
   "source": [
    "# Available in: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.13\n",
    "\n",
    "names_tyc={}\n",
    "names_tyc[1] = \"tycho2_id\"\n",
    "names_tyc[8] = \"ra_tyc\"\n",
    "names_tyc[9] = \"dec_tyc\"\n",
    "names_tyc[11] = \"parallax_tyc\"\n",
    "names_tyc[12] = \"pmra_tyc\"\n",
    "names_tyc[13] = \"pmdec_tyc\"\n",
    "names_tyc[14] = \"ra_error_tyc\"\n",
    "names_tyc[15] = \"dec_error_tyc\"\n",
    "names_tyc[16] = \"parallax_error_tyc\"\n",
    "names_tyc[17] = \"pmra_error_tyc\"\n",
    "names_tyc[18] = \"pmdec_error_tyc\"\n",
    "names_tyc[19] = \"ra_dec_corr_tyc\"\n",
    "names_tyc[20] = \"ra_parallax_corr_tyc\"\n",
    "names_tyc[21] = \"dec_parallax_corr_tyc\"\n",
    "names_tyc[22] = \"ra_pmra_corr_tyc\"\n",
    "names_tyc[23] = \"dec_pmra_corr_tyc\"\n",
    "names_tyc[24] = \"parallax_pmra_corr_tyc\"\n",
    "names_tyc[25] = \"ra_pmdec_corr_tyc\"\n",
    "names_tyc[26] = \"dec_pmdec_corr_tyc\"\n",
    "names_tyc[27] = \"parallax_pmdec_corr_tyc\"\n",
    "names_tyc[28] = \"pmra_pmdec_corr_tyc\"\n",
    "names_tyc[53] = \"HenryDraperId_tyc\"\n",
    "names_tyc[5] = \"Vmag_tyc\"\n",
    "\n",
    "names_tyc = collections.OrderedDict(sorted(names_tyc.items()))\n",
    "\n",
    "tycho = pd.read_csv(dir_hip + \"tyc_main.zip\", delimiter=\"|\", usecols = names_tyc.keys(), names = names_tyc.values())\n",
    "\n",
    "# Split original tycho-id header which separated by white-space\n",
    "tycho[\"a\"], tycho[\"b\"], tycho[\"c\"] = tycho[\"tycho2_id\"].str.split().str\n",
    "\n",
    "# Concatenate tycho-id headers using \"-\"\n",
    "tycho[\"tycho2_id\"] = tycho[\"a\"] + \"-\" + tycho[\"b\"] + \"-\" + tycho[\"c\"]\n",
    "\n",
    "# Delete auxiliar columns used in conversion\n",
    "del tycho[\"a\"], tycho[\"b\"], tycho[\"c\"]\n",
    "\n",
    "# Columns format\n",
    "cols = tycho.columns.tolist()\n",
    "objects = [\"tycho2_id\", \"HenryDraperId_tyc\"]\n",
    "cols = [x for x in cols if x not in objects]\n",
    "tycho[cols] = tycho[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Delete null astrometry values\n",
    "n1 = len(tycho)\n",
    "tycho.dropna(subset=[\"ra_tyc\", \"dec_tyc\", \"parallax_tyc\"], how=\"any\", inplace=True)\n",
    "n2 = len(tycho)\n",
    "print(\"\\nDatabase Tycho:\", \"\\nOriginal objects:\", n1,\"\\nDiscarded objects:\", n1-n2,\"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Load Simbad-Hipparcos database\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Simbad: \n",
      "Original objects: 118179 \n",
      "Discarded objects: 175 \n",
      "Final objects: 118004\n"
     ]
    }
   ],
   "source": [
    "cols = [\"typedident\",\"identifier\", \"radvel\", \"coord1(ICRS,J2000/2000)\", \"plx\", \"pm\", \"MagV\", \"spec.type\"]\n",
    "simbad = pd.read_csv(dir_simbad + \"simbad.zip\", usecols=cols, delimiter=\"|\")\n",
    "\n",
    "# Modify ID\n",
    "simbad[\"hip\"] = simbad[\"typedident\"].map(lambda x: str(x)[4:]).astype(str)\n",
    "simbad[\"hip\"] = simbad[\"hip\"].str.strip()\n",
    "del simbad[\"typedident\"]\n",
    "\n",
    "# Right ascension and declination format\n",
    "# 1. Delete white-spaces on both sides of the text\n",
    "simbad[\"coord1(ICRS,J2000/2000)\"] = simbad[\"coord1(ICRS,J2000/2000)\"].str.strip()\n",
    "\n",
    "# 2. Split string into 6 values (hh:mm:ss for RA and hh:mm:ss for DEC)\n",
    "simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"] = \\\n",
    "    simbad[\"coord1(ICRS,J2000/2000)\"].str.split(\" \").str\n",
    "\n",
    "# 3. Concatenate the first 3 fields (RA) using conversion formule from hh:mm:ss to degrees\n",
    "simbad[\"ra_simbad\"] = simbad[\"ra_h\"].astype(float)*15 + simbad[\"ra_m\"].astype(float)/60 + simbad[\"ra_s\"].astype(float)/3600\n",
    "\n",
    "# 4. Concatenate the last 3 fields (DEC) using conversion formule from hh:mm:ss to degrees\n",
    "simbad[\"dec_simbad\"] = np.sign(simbad[\"dec_h\"].astype(float)) * ( \\\n",
    "    np.abs(simbad[\"dec_h\"].astype(float)) + simbad[\"dec_m\"].astype(float)/60 + simbad[\"dec_s\"].astype(float)/3600 )\n",
    "\n",
    "# 5. Delete auxiliar columns used in conversion\n",
    "del simbad[\"coord1(ICRS,J2000/2000)\"]\n",
    "del simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"]\n",
    "\n",
    "# Proper motion format\n",
    "# 1. Delete white-spaces on both sides of the text\n",
    "simbad[\"pm\"] = simbad[\"pm\"].str.strip()\n",
    "\n",
    "# 2. Split string into 2 values (pm_ra and pm_dec)\n",
    "simbad[\"pmra_simbad\"], simbad[\"pmdec_simbad\"] = simbad[\"pm\"].str.split(\" \").str\n",
    "\n",
    "# 3. Delete auxiliar columns used in conversion\n",
    "del simbad[\"pm\"]\n",
    "\n",
    "# Modify name columns\n",
    "simbad = simbad.rename(columns={\"identifier\": \"name_simbad\"})\n",
    "simbad = simbad.rename(columns={\"plx\": \"parallax_simbad\"})   \n",
    "simbad = simbad.rename(columns={\"spec.type\": \"sptype_simbad\"})     \n",
    "simbad = simbad.rename(columns={\"radvel\": \"RV_simbad\"})    \n",
    "simbad = simbad.rename(columns={\"MagV\": \"Vmag_simbad\"})\n",
    "\n",
    "# Columns format\n",
    "cols = simbad.columns.tolist()\n",
    "objects = [\"hip\", \"name_simbad\", \"sptype_simbad\"]\n",
    "cols = [x for x in cols if x not in objects]\n",
    "simbad[cols] = simbad[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Delete null astrometry values\n",
    "n1 = len(simbad)\n",
    "simbad.dropna(subset=[\"ra_simbad\", \"dec_simbad\", \"parallax_simbad\"], how=\"any\", inplace=True)      \n",
    "n2 = len(simbad)\n",
    "\n",
    "print(\"\\nDatabase Simbad:\", \"\\nOriginal objects:\", n1,\"\\nDiscarded objects:\", n1-n2,\"\\nFinal objects:\", n2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Create database with unique astrometry values\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building database with just one astrometry source per star:\n",
      "Input from Hipparcos: 24557\n",
      "Input from Tycho: 266121\n",
      "Input from Simbad: 67\n",
      "Total lenght: 2316955\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding database with just one astrometry source per star:\")\n",
    "\n",
    "# db = Gaia + Hipparcos\n",
    "db = pd.DataFrame()\n",
    "gaia[\"source_astro\"] = \"gaia\"\n",
    "exclusive_hip = hipparcos[~hipparcos.hip.isin(gaia_hip.hip)]\n",
    "exclusive_hip.rename(columns=lambda x: x.replace(\"_hip\", \"\"), inplace=True)\n",
    "exclusive_hip[\"source_astro\"] = \"hipparcos\"\n",
    "db = pd.concat([gaia, exclusive_hip], axis=0)\n",
    "print(\"Input from Hipparcos:\", len(exclusive_hip))\n",
    "\n",
    "# db = db + Tycho\n",
    "exclusive_tyc = tycho[~tycho.tycho2_id.isin(gaia_tyc.tycho2_id)]\n",
    "exclusive_tyc.rename(columns=lambda x: x.replace(\"_tyc\", \"\"), inplace=True)\n",
    "exclusive_tyc[\"source_astro\"] = \"tycho\"\n",
    "db = pd.concat([db, exclusive_tyc], axis=0)\n",
    "print(\"Input from Tycho:\", len(exclusive_tyc))\n",
    "\n",
    "# db = db + Simbad\n",
    "exclusive_simbad = simbad[~simbad.hip.isin(db.hip)]\n",
    "exclusive_simbad.rename(columns=lambda x: x.replace(\"_simbad\", \"\"), inplace=True)\n",
    "exclusive_simbad = exclusive_simbad.loc[:,[\"hip\", \"ra\", \"dec\", \"parallax\", \"pmra\", \"pmdec\"]]\n",
    "exclusive_simbad[\"source_astro\"] = \"simbad\"\n",
    "db = pd.concat([db, exclusive_simbad], axis=0)\n",
    "print(\"Input from Simbad:\", len(exclusive_simbad))\n",
    "\n",
    "# Clean np.NaN in objects produced by concat method\n",
    "db.replace({\"hip\":{np.NaN:\"\"},\"tycho2_id\":{np.NaN:\"\"},\"source_id\":{np.NaN:\"\"},\"HenryDraperId\":{np.NaN:\"\"}}, inplace=True)\n",
    "\n",
    "# Merge db + Simbad new columns\n",
    "db = db.merge(simbad[[\"hip\", \"name_simbad\",\"sptype_simbad\",\"RV_simbad\",\"Vmag_simbad\"]], on=\"hip\", how=\"left\")\n",
    "\n",
    "# Merge db + HipVanLeeuwen2007 new columns\n",
    "db = db.merge(hipvan[['hip', 'Hpmag_hip', 'e_Hpmag_hip', 'B_V_hip', 'e_B_V_hip', 'V_I_hip']], on='hip', how='left')\n",
    "\n",
    "#db[\"id\"] = db.hip.combine(db.tycho2_id, lambda x, y: x if x is not \"\" else y)\n",
    "db[\"id\"] = db.hip.astype(str) + db.tycho2_id.astype(str)\n",
    "\n",
    "# Change the order of database columns\n",
    "cols = [\"id\", \"source_astro\"] + cols_gaia + [\"Vmag\",\"HenryDraperId\"] + \\\n",
    "       [\"name_simbad\",\"sptype_simbad\",\"RV_simbad\",\"Vmag_simbad\"] + \\\n",
    "       ['Hpmag_hip', 'e_Hpmag_hip', 'B_V_hip', 'e_B_V_hip', 'V_I_hip']\n",
    "db = db[cols]\n",
    "db = db.reset_index(drop=True)\n",
    "\n",
    "print(\"Total lenght:\", len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(db.hip!=\"\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Full database with the information of all the catalogs\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging astrometry databases (it keeps data of all sources):\n",
      "Gaia objects (initial lenght of database): 2026210\n",
      "Hipparcos objects: 117955 | Input from Hipparcos: 24557 | Final lenght of database: 2050767\n",
      "Hipparcos improved objects: 117955 | Input from Hipparcos improved: 0 | Final lenght of database: 2050767\n",
      "Tycho objects: 1035445 | Input from Tycho: 266121 | Final lenght of database: 2316888\n",
      "Simbad objects: 118004 | Input from Simbad: 67 | Final lenght of database: 2316955\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerging astrometry databases (it keeps data of all sources):\")\n",
    "\n",
    "database = pd.DataFrame()\n",
    "\n",
    "n1 = len(gaia)\n",
    "print(\"Gaia objects (initial lenght of database):\", n1)\n",
    "\n",
    "database = gaia.merge(hipparcos, on=\"hip\", how=\"outer\")\n",
    "n2 = len(database)\n",
    "print(\"Hipparcos objects:\", len(hipparcos), \"| Input from Hipparcos:\", n2-n1, \"| Final lenght of database:\", n2)\n",
    "\n",
    "database = database.merge(hipvan, on=\"hip\", how=\"outer\")\n",
    "n21 = len(database)\n",
    "print(\"Hipparcos improved objects:\", len(hipvan), \"| Input from Hipparcos improved:\", n21-n2, \"| Final lenght of database:\", n21)\n",
    "\n",
    "database = database.merge(tycho, on=\"tycho2_id\", how=\"outer\")\n",
    "n3 = len(database)\n",
    "print(\"Tycho objects:\", len(tycho), \"| Input from Tycho:\", n3-n2, \"| Final lenght of database:\", n3)\n",
    "\n",
    "database = database.merge(simbad, on=\"hip\", how=\"outer\")\n",
    "n4 = len(database)\n",
    "print(\"Simbad objects:\", len(simbad),  \"| Input from Simbad:\", n4-n3, \"| Final lenght of database:\", n4)\n",
    "\n",
    "#database[\"id\"] = database.hip.combine(database.tycho2_id, lambda x, y: x if x is not \"\" else y)\n",
    "database[\"id\"] = database.hip.astype(str) + database.tycho2_id.astype(str)\n",
    "\n",
    "database = database.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hip', 'tycho2_id', 'source_id', 'ra', 'ra_error', 'dec', 'dec_error',\n",
       "       'parallax', 'parallax_error', 'pmra', 'pmra_error', 'pmdec',\n",
       "       'pmdec_error', 'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr',\n",
       "       'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
       "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',\n",
       "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_g_mean_mag', 'l',\n",
       "       'b', 'ecl_lon', 'ecl_lat', 'source_astro', 'Vmag_hip', 'ra_hip_x',\n",
       "       'dec_hip_x', 'ra_error_hip', 'dec_error_hip', 'ra_dec_corr_hip',\n",
       "       'ra_parallax_corr_hip', 'dec_parallax_corr_hip', 'ra_pmra_corr_hip',\n",
       "       'dec_pmra_corr_hip', 'parallax_pmra_corr_hip', 'ra_pmdec_corr_hip',\n",
       "       'dec_pmdec_corr_hip', 'parallax_pmdec_corr_hip', 'pmra_pmdec_corr_hip',\n",
       "       'HenryDraperId_hip', 'parallax_hip_x', 'pmra_hip_x', 'pmdec_hip_x',\n",
       "       'parallax_error_hip_x', 'pmra_error_hip_x', 'pmdec_error_hip_x',\n",
       "       'ra_hip_y', 'dec_hip_y', 'parallax_hip_y', 'parallax_error_hip_y',\n",
       "       'pmra_hip_y', 'pmra_error_hip_y', 'pmdec_hip_y', 'pmdec_error_hip_y',\n",
       "       'Hpmag_hip', 'e_Hpmag_hip', 'B_V_hip', 'e_B_V_hip', 'V_I_hip',\n",
       "       'Vmag_tyc', 'ra_tyc', 'dec_tyc', 'parallax_tyc', 'pmra_tyc',\n",
       "       'pmdec_tyc', 'ra_error_tyc', 'dec_error_tyc', 'parallax_error_tyc',\n",
       "       'pmra_error_tyc', 'pmdec_error_tyc', 'ra_dec_corr_tyc',\n",
       "       'ra_parallax_corr_tyc', 'dec_parallax_corr_tyc', 'ra_pmra_corr_tyc',\n",
       "       'dec_pmra_corr_tyc', 'parallax_pmra_corr_tyc', 'ra_pmdec_corr_tyc',\n",
       "       'dec_pmdec_corr_tyc', 'parallax_pmdec_corr_tyc', 'pmra_pmdec_corr_tyc',\n",
       "       'HenryDraperId_tyc', 'name_simbad', 'parallax_simbad', 'RV_simbad',\n",
       "       'Vmag_simbad', 'sptype_simbad', 'ra_simbad', 'dec_simbad',\n",
       "       'pmra_simbad', 'pmdec_simbad', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Load radial velocities databases\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial velocity databases:\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(\"\\nRadial velocity databases:\")\n",
    "radialv = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAVE-DR5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RAVE-DR5.tsv \n",
      "Original objects: 520701 \n",
      "Discarded: 0 \n",
      "Final objects: 520701\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RAVE-DR5\n",
    "# =============================================================================\n",
    "\n",
    "file = \"RAVE-DR5.tsv\"\n",
    "cols = [\"HRV\", \"e_HRV\", \"TGAS\", \"TYCHO2\"]\n",
    "delimiter = \";\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                                skiprows = list(np.arange(78)) + [79, 80]))\n",
    "\n",
    "data.rename(columns={\"HRV\": \"RV\", \"e_HRV\": \"e_RV\", \"TGAS\": \"source_id\", \"TYCHO2\": \"tycho2_id\"}, inplace=True)\n",
    "data = data.merge(gaia.loc[:,[\"source_id\",\"hip\"]], left_on=\"source_id\", right_on=\"source_id\", how=\"left\")\n",
    "data.source_id = data.source_id.str.strip()\n",
    "data.tycho2_id = data.tycho2_id.str.strip()\n",
    "data.hip.replace(np.nan,\"\", inplace=True)\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BB2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BB2000.csv \n",
      "Original objects: 673 \n",
      "Discarded: 0 \n",
      "Final objects: 673\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BB2000\n",
    "# =============================================================================\n",
    "\n",
    "file = \"BB2000.csv\"\n",
    "cols = [\"RV\", \"e_RV\", \"TYC1\", \"TYC2\", \"TYC3\"]\n",
    "delimiter = \",\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter))\n",
    "\n",
    "data[\"tycho2_id\"] = data.TYC1.astype(str) + \"-\" + data.TYC2.astype(str) + \"-\" + data.TYC3.astype(str)\n",
    "del data[\"TYC1\"], data[\"TYC2\"], data[\"TYC3\"]\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Famaey2005.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Famaey2005.tsv \n",
      "Original objects: 6690 \n",
      "Discarded: 662 \n",
      "Final objects: 6028\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Famaey2005.tsv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Famaey2005.tsv\"\n",
    "cols = [\"RV\", \"e_RV\", \"HIP\"]\n",
    "delimiter = \";\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                                skiprows = list(np.arange(118)) + [119, 120]))\n",
    "\n",
    "data.rename(columns={\"HIP\": \"hip\"}, inplace=True)\n",
    "data.hip = data.hip.astype(str)\n",
    "data.RV = pd.to_numeric(data.RV, errors=\"coerce\")\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galah.tsv - Without e_RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Galah.tsv \n",
      "Original objects: 10680 \n",
      "Discarded: 0 \n",
      "Final objects: 10680\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Galah.tsv - Without e_RV\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Galah.tsv\"\n",
    "cols = [\"RV\", \"TYC2\"]\n",
    "delimiter = \";\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                                skiprows = list(np.arange(54)) + [55, 56]))\n",
    "\n",
    "data.rename(columns={\"TYC2\": \"tycho2_id\"}, inplace=True)\n",
    "data[\"tycho2_id\"] = data[\"tycho2_id\"].map(lambda x: x.replace(\"-\", \" \"))\n",
    "data[\"a\"], data[\"b\"], data[\"c\"] = data[\"tycho2_id\"].str.split().str\n",
    "data[\"a\"] = pd.to_numeric(data[\"a\"])\n",
    "data[\"b\"] = pd.to_numeric(data[\"b\"])\n",
    "data[\"c\"] = pd.to_numeric(data[\"c\"])\n",
    "data[\"tycho2_id\"] = data[\"a\"].astype(str) + \"-\" + data[\"b\"].astype(str) + \"-\" + data[\"c\"].astype(str)\n",
    "del data[\"a\"], data[\"b\"], data[\"c\"]\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Without_info\"\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCS2011.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GCS2011.tsv \n",
      "Original objects: 16682 \n",
      "Discarded: 2543 \n",
      "Final objects: 14139\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GCS2011.tsv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"GCS2011.tsv\"\n",
    "cols = [\"RV\", \"e_RV\", \"HIP\", \"Name\"]\n",
    "delimiter = \"|\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                               skiprows = list(np.arange(174)) + [175, 176]))\n",
    "\n",
    "data.rename(columns={\"HIP\":\"hip\", \"Name\":\"name\"}, inplace=True)\n",
    "data.RV = pd.to_numeric(data.RV, errors=\"coerce\")\n",
    "data.e_RV = pd.to_numeric(data.e_RV, errors=\"coerce\")\n",
    "data.hip = data.hip.str.strip()\n",
    "data.name = data.name.str.strip()\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaroda2012.csv - Without e_RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Malaroda2012.csv \n",
      "Original objects: 2178 \n",
      "Discarded: 146 \n",
      "Final objects: 2032\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Malaroda2012.csv - Without e_RV\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Malaroda2012.csv\"\n",
    "cols = [\"RV\", \"HIP\", \"TYC1\", \"TYC2\", \"TYC3\"]\n",
    "delimiter = \",\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter))\n",
    "\n",
    "data.rename(columns={\"HIP\":\"hip\"}, inplace=True)\n",
    "\n",
    "data[\"tycho2_id\"] = data.TYC1.astype(str) + \"-\" + data.TYC2.astype(str) + \"-\" + data.TYC3.astype(str)\n",
    "del data[\"TYC1\"], data[\"TYC2\"], data[\"TYC3\"]\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Without_info\"\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maldonado2010.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Maldonado2010.tsv \n",
      "Original objects: 495 \n",
      "Discarded: 22 \n",
      "Final objects: 473\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Maldonado2010.tsv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Maldonado2010.tsv\"\n",
    "cols = [\"RV\", \"e_RV\", \"HIP\"]\n",
    "delimiter = \";\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                               skiprows = list(np.arange(82)) + [83, 84]))\n",
    "\n",
    "data.rename(columns={\"HIP\":\"hip\"}, inplace=True)\n",
    "data.RV = pd.to_numeric(data.RV, errors=\"coerce\")\n",
    "data.e_RV = pd.to_numeric(data.e_RV, errors=\"coerce\")\n",
    "data.hip = data.hip.astype(str)\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulkovo.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pulkovo.tsv \n",
      "Original objects: 35493 \n",
      "Discarded: 0 \n",
      "Final objects: 35493\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Pulkovo.tsv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Pulkovo.tsv\"\n",
    "cols = [\"RV\", \"e_RV\", \"HIP\"]\n",
    "delimiter = \";\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter, \n",
    "                               skiprows = list(np.arange(61)) + [62, 63]))\n",
    "\n",
    "data.rename(columns={\"HIP\":\"hip\"}, inplace=True)\n",
    "data.hip = data.hip.astype(str)\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "#median = data.e_RV[data.e_RV>0].median()\n",
    "#data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web1995-HIP.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Web1995-HIP.csv \n",
      "Original objects: 494 \n",
      "Discarded: 0 \n",
      "Final objects: 494\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Web1995-HIP.csv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Web1995-HIP.csv\"\n",
    "cols = [\"RV\", \"e_RV\", \"HIP\"]\n",
    "delimiter = \",\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter))\n",
    "\n",
    "data.rename(columns={\"HIP\":\"hip\"}, inplace=True)\n",
    "data.hip = data.hip.astype(str)\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web1995-TYC2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Web1995-TYC2.csv \n",
      "Original objects: 673 \n",
      "Discarded: 0 \n",
      "Final objects: 673\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Web1995-TYC2.csv\n",
    "# =============================================================================\n",
    "\n",
    "file = \"Web1995-TYC2.csv\"\n",
    "cols = [\"RV\", \"e_RV\", \"TYC1\", \"TYC2\", \"TYC3\"]\n",
    "delimiter = \",\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter))\n",
    "\n",
    "data[\"tycho2_id\"] = data.TYC1.astype(str) + \"-\" + data.TYC2.astype(str) + \"-\" + data.TYC3.astype(str)\n",
    "del data[\"TYC1\"], data[\"TYC2\"], data[\"TYC3\"]\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "data.source_erv[data.e_RV.isnull()] = \"median\"\n",
    "median = data.e_RV[data.e_RV>0].median()\n",
    "data.e_RV[data.e_RV.isnull()] = median\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APOGEE2 (taken from RVcat of Bailer-Jones 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RVcat.csv.zip \n",
      "Original objects: 29173 \n",
      "Discarded: 0 \n",
      "Final objects: 29173\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RVcat.csv.zip\n",
    "# =============================================================================\n",
    "file = \"RVcat.csv.zip\"\n",
    "cols = [\"RV\", \"RVerr\", \"tychoID\",\"cat\"]\n",
    "delimiter = \",\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data = pd.DataFrame(pd.read_csv(dir_rv + file, usecols=cols, delimiter=delimiter))\n",
    "\n",
    "#Choose only objects from apogee database\n",
    "data = data[data.cat==10]\n",
    "\n",
    "data.rename(columns={\"RVerr\":\"e_RV\", \"tychoID\":\"tycho2_id\"}, inplace=True)\n",
    "\n",
    "data[\"source_rv\"] = file\n",
    "data[\"source_erv\"] = \"Catalogue\"\n",
    "n1 = len(data)\n",
    "data.dropna(subset=[\"e_RV\"], inplace=True)\n",
    "data.dropna(subset=[\"RV\"], inplace=True)\n",
    "n2 = len(data)\n",
    "radialv[file] = data\n",
    "print(\"\\n\", file, \"\\nOriginal objects:\", n1, \"\\nDiscarded:\", n1-n2, \"\\nFinal objects:\", n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Radial velocity databases integration\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial velocity databases integration:\n",
      "Objects number with different VR and e_VR combination: 394772\n",
      "Objects number with different VR and the same minimun e_VR: 325242\n",
      "Objects number without duplicates (just one register per star): 323589\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRadial velocity databases integration:\")\n",
    "\n",
    "t2 = time.time()\n",
    "RV = pd.DataFrame()\n",
    "RV = pd.concat([radialv[\"RAVE-DR5.tsv\"], radialv[\"BB2000.csv\"], radialv[\"Famaey2005.tsv\"], \n",
    "                radialv[\"Galah.tsv\"], radialv[\"GCS2011.tsv\"], radialv[\"Malaroda2012.csv\"], \n",
    "                radialv[\"Maldonado2010.tsv\"], radialv[\"Pulkovo.tsv\"], radialv[\"Web1995-HIP.csv\"], \n",
    "                radialv[\"Web1995-TYC2.csv\"], radialv[\"RVcat.csv.zip\"]], axis = 0)\n",
    "RV.hip.replace(np.NaN, \"\", inplace=True)\n",
    "RV.tycho2_id.replace(np.NaN, \"\", inplace=True)\n",
    "RV.source_id.replace(np.NaN, \"\", inplace=True)\n",
    "RV.name.replace(np.NaN, \"\", inplace=True)\n",
    "RV[\"id\"] = RV.hip.astype(str) + RV.tycho2_id.astype(str)\n",
    "\n",
    "# Drop objects with incomplete astrometry information or with both RV and e_RV duplicates\n",
    "RV1 = RV.copy()\n",
    "RV1 = RV1[RV1.e_RV.notnull()]\n",
    "RV1 = RV1[RV1.id != \"\"]\n",
    "\n",
    "# RV1 => Various records per star with different VR and e_VR combination are allowed\n",
    "RV1.drop_duplicates(subset=[\"id\",\"RV\",\"e_RV\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# RV2 => Keep only object with minimum e_RV value (various records per star with the same e_VR are allowed)\n",
    "RV2 = pd.DataFrame()\n",
    "RV_min_eRV = RV1.groupby(\"id\", as_index=False).e_RV.min()\n",
    "RV2 = RV1.merge(RV_min_eRV, on=[\"id\",\"e_RV\"], how=\"inner\")\n",
    "\n",
    "# RV3 => Keep only one object with minimum e_RV value (Just one record per star is allowed)\n",
    "RV3 = pd.DataFrame()\n",
    "RV3 = RV2.drop_duplicates(subset=[\"id\",\"e_RV\"], keep=\"first\")\n",
    "\n",
    "print(\"Objects number with different VR and e_VR combination:\", len(RV1))\n",
    "print(\"Objects number with different VR and the same minimun e_VR:\", len(RV2))\n",
    "print(\"Objects number without duplicates (just one register per star):\", len(RV3))\n",
    "\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RV', 'cat', 'e_RV', 'hip', 'name', 'source_erv', 'source_id',\n",
       "       'source_rv', 'tycho2_id', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RV.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## Full integration\n",
    "## ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objects in AstroRV (without duplicates): 289345\n",
      "\n",
      "Objects in AstroRV per source: source_rv\n",
      "BB2000.csv              600\n",
      "Famaey2005.tsv         5551\n",
      "GCS2011.tsv            7096\n",
      "Maldonado2010.tsv       301\n",
      "Pulkovo.tsv           23618\n",
      "RAVE-DR5.tsv         227668\n",
      "RVcat.csv.zip         24258\n",
      "Web1995-HIP.csv         253\n",
      "Name: source_rv, dtype: int64\n",
      "Number of objects with hipparcos id: 36918\n",
      "Number of objects with tycho2 id: 252427\n"
     ]
    }
   ],
   "source": [
    "# Building AstroRV's databases\n",
    "AstroRVDuplicates = pd.DataFrame()\n",
    "AstroRVDuplicates = db.merge(RV1[[\"id\", \"RV\", \"e_RV\", \"source_rv\", \"source_erv\"]], on=\"id\", how=\"right\")\n",
    "\n",
    "AstroRV = pd.DataFrame()\n",
    "AstroRV = db.merge(RV3[[\"id\", \"RV\", \"e_RV\", \"source_rv\", \"source_erv\"]], on=\"id\", how=\"right\")\n",
    "\n",
    "# Drop objects with incomplet astrometry information\n",
    "AstroRVDuplicates.dropna(subset=[\"parallax\"], inplace=True)\n",
    "AstroRV.dropna(subset=[\"parallax\"], inplace=True)\n",
    "\n",
    "AstroRVDuplicates.to_csv(dir_results + \"AstroRVDuplicates.csv\", index=False)\n",
    "AstroRV.to_csv(dir_results + \"AstroRV_2.csv\", index=False)\n",
    "\n",
    "print(\"\\nObjects in AstroRV (without duplicates):\", len(AstroRV))\n",
    "print(\"\\nObjects in AstroRV per source:\", AstroRV.groupby(AstroRV.source_rv).source_rv.count())\n",
    "\n",
    "print(\"Number of objects with hipparcos id:\",(AstroRV.hip!=\"\").sum())\n",
    "print(\"Number of objects with tycho2 id:\",(AstroRV.tycho2_id!=\"\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gmag: 37826\n",
      "No Vmag: 251528\n",
      "No Vmag_simbad: 252604\n",
      "No magnitude: 0\n"
     ]
    }
   ],
   "source": [
    "#Number of stars without magnitude\n",
    "print(\"No gmag:\",(AstroRV.phot_g_mean_mag.isnull()).sum())\n",
    "print(\"No Vmag:\",(AstroRV.Vmag.isnull()).sum())\n",
    "print(\"No Vmag_simbad:\",(AstroRV.Vmag_simbad.isnull()).sum())\n",
    "print(\"No magnitude:\",(AstroRV.phot_g_mean_mag.isnull()&AstroRV.Vmag.isnull()&AstroRV.Vmag_simbad.isnull()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'source_astro', 'source_id', 'hip', 'tycho2_id', 'ra', 'ra_error',\n",
       "       'dec', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error',\n",
       "       'pmdec', 'pmdec_error', 'ra_dec_corr', 'ra_parallax_corr',\n",
       "       'ra_pmra_corr', 'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr',\n",
       "       'dec_pmdec_corr', 'parallax_pmra_corr', 'parallax_pmdec_corr',\n",
       "       'pmra_pmdec_corr', 'phot_g_mean_flux', 'phot_g_mean_flux_error',\n",
       "       'phot_g_mean_mag', 'l', 'b', 'ecl_lon', 'ecl_lat', 'Vmag',\n",
       "       'HenryDraperId', 'name_simbad', 'sptype_simbad', 'RV_simbad',\n",
       "       'Vmag_simbad', 'Hpmag_hip', 'e_Hpmag_hip', 'B_V_hip', 'e_B_V_hip',\n",
       "       'V_I_hip', 'RV', 'e_RV', 'source_rv', 'source_erv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AstroRV.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects with hipparcos id: 289345\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of objects with hipparcos id:\",(AstroRV.id!=\"\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289345\n"
     ]
    }
   ],
   "source": [
    "print(len(AstroRV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             55-72-1\n",
       "1           48-1138-1\n",
       "2           55-1269-1\n",
       "3           55-1181-1\n",
       "4                    \n",
       "5           55-1308-1\n",
       "6            48-685-1\n",
       "7            48-120-1\n",
       "8           48-1076-1\n",
       "9           48-1215-1\n",
       "10                   \n",
       "11           55-551-1\n",
       "12           55-268-1\n",
       "13          48-1105-1\n",
       "14           55-640-1\n",
       "15           55-998-1\n",
       "16           55-642-1\n",
       "17           55-954-1\n",
       "18           55-112-1\n",
       "19           55-357-1\n",
       "20          58-1235-1\n",
       "21          58-1074-1\n",
       "22                   \n",
       "23          58-1002-1\n",
       "24          58-1088-1\n",
       "25                   \n",
       "26                   \n",
       "27           58-581-1\n",
       "28                   \n",
       "29           48-808-1\n",
       "             ...     \n",
       "289315     9528-260-1\n",
       "289316     9528-558-1\n",
       "289317     9528-622-1\n",
       "289318     9528-709-1\n",
       "289319    9528-1035-1\n",
       "289320    9528-1205-1\n",
       "289321    9528-1520-1\n",
       "289322    9528-2176-1\n",
       "289323      9529-46-1\n",
       "289324     9529-382-1\n",
       "289325     9529-526-1\n",
       "289326     9529-642-1\n",
       "289327     9529-878-1\n",
       "289328    9529-1096-1\n",
       "289329    9529-1330-1\n",
       "289330    9529-1463-1\n",
       "289331     9530-206-1\n",
       "289332     9530-306-1\n",
       "289333    9530-1228-1\n",
       "289334    9531-1082-1\n",
       "289335     9533-797-1\n",
       "289336               \n",
       "289337               \n",
       "289338               \n",
       "289339               \n",
       "289340               \n",
       "289341               \n",
       "289342               \n",
       "289343               \n",
       "289344               \n",
       "Name: tycho2_id, Length: 289345, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AstroRV.tycho2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'source_astro', 'source_id', 'hip', 'tycho2_id', 'ra', 'ra_error',\n",
       "       'dec', 'dec_error', 'parallax', 'parallax_error', 'pmra', 'pmra_error',\n",
       "       'pmdec', 'pmdec_error', 'ra_dec_corr', 'ra_parallax_corr',\n",
       "       'ra_pmra_corr', 'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr',\n",
       "       'dec_pmdec_corr', 'parallax_pmra_corr', 'parallax_pmdec_corr',\n",
       "       'pmra_pmdec_corr', 'phot_g_mean_flux', 'phot_g_mean_flux_error',\n",
       "       'phot_g_mean_mag', 'l', 'b', 'ecl_lon', 'ecl_lat', 'Vmag',\n",
       "       'HenryDraperId', 'name_simbad', 'sptype_simbad', 'RV_simbad',\n",
       "       'Vmag_simbad', 'Hpmag_hip', 'e_Hpmag_hip', 'B_V_hip', 'e_B_V_hip',\n",
       "       'V_I_hip', 'RV', 'e_RV', 'source_rv', 'source_erv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AstroRV.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
