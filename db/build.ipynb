{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build AstroRV Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed to build the AstroRV catalog, a complete compilation of astrometric and radial velocities information of nearby stars. \n",
    "\n",
    "This catalog was originally aimed at studying the interstellar origin probability for objects approaching the Solar System in unbound orbits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAIA SOURCES\n",
    "TGAS_DIR=\"DataGAIA/Data-Gaia/\"\n",
    "\n",
    "#SIMBAD SOURCES\n",
    "SIMBAD_DIR=\"DataGAIA/Data-Simbad/\"\n",
    "\n",
    "#TYCHO2/HIPPARCOS SOURCES\n",
    "HIPTYC_DIR=\"DataGAIA/Data-Hipparcos/\"\n",
    "\n",
    "#RADIAL VELOCITY SOURCES\n",
    "RV_DIR=\"RVGaia/RV/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-000.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-001.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-002.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-003.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-004.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-005.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-006.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-007.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-008.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-009.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-010.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-011.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-012.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-013.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-014.csv.gz\n",
      "Reading DataGAIA/Data-Gaia//TgasSource_000-000-015.csv.gz\n"
     ]
    }
   ],
   "source": [
    "cols_gaia = [\"hip\", \"tycho2_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"parallax\", \"parallax_error\", \"pmra\", \"pmra_error\", \\\n",
    "             \"pmdec\", \"pmdec_error\", \"ra_dec_corr\", \"ra_parallax_corr\", \"ra_pmra_corr\", \"ra_pmdec_corr\", \"dec_parallax_corr\", \\\n",
    "             \"dec_pmra_corr\", \"dec_pmdec_corr\", \"parallax_pmra_corr\", \"parallax_pmdec_corr\", \"pmra_pmdec_corr\", \\\n",
    "             \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"phot_g_mean_mag\", \"l\", \"b\", \"ecl_lon\", \"ecl_lat\"]\n",
    "\n",
    "for i in range(16):\n",
    "    filename = TGAS_DIR + \"TgasSource_000-000-0\" + str(i).zfill(2) + \".csv.gz\"\n",
    "    if i == 0:\n",
    "        print(\"Reading\", filename)\n",
    "        gaia = pd.read_csv(filename, usecols=cols_gaia)\n",
    "    else:\n",
    "        print(\"Reading\", filename)\n",
    "        DRx = pd.read_csv(filename, usecols=cols_gaia)\n",
    "        gaia = gaia.append(DRx)\n",
    "\n",
    "gaia = pd.DataFrame(gaia)\n",
    "\n",
    "cats=['hip','tycho2_id']\n",
    "for cname in cats:\n",
    "    gaia[cname]=gaia[cname].fillna('')\n",
    "    gaia[cname]=gaia[cname].map(str)\n",
    "dfstr=gaia.select_dtypes(['object'])\n",
    "gaia[dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "gaia['hip']=gaia['hip'].apply(lambda x:x.replace('.0',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIPPARCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117955"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Información disponible en: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.1\n",
    "names_hip={}\n",
    "names_hip[1] = \"hip\"\n",
    "names_hip[8] = \"ra_Hip\"\n",
    "names_hip[9] = \"dec_Hip\"\n",
    "names_hip[11] = \"parallax_Hip\"\n",
    "names_hip[12] = \"pmra_Hip\"\n",
    "names_hip[13] = \"pmdec_Hip\"\n",
    "names_hip[14] = \"ra_error_Hip\"\n",
    "names_hip[15] = \"dec_error_Hip\"\n",
    "names_hip[16] = \"parallax_error_Hip\"\n",
    "names_hip[17] = \"pmra_error_Hip\"\n",
    "names_hip[18] = \"pmdec_error_Hip\"\n",
    "names_hip[19] = \"ra_dec_corr_Hip\"\n",
    "names_hip[20] = \"ra_parallax_corr_Hip\"\n",
    "names_hip[21] = \"dec_parallax_corr_Hip\"\n",
    "names_hip[22] = \"ra_pmra_corr_Hip\"\n",
    "names_hip[23] = \"dec_pmra_corr_Hip\"\n",
    "names_hip[24] = \"parallax_pmra_corr_Hip\"\n",
    "names_hip[25] = \"ra_pmdec_corr_Hip\"\n",
    "names_hip[26] = \"dec_pmdec_corr_Hip\"\n",
    "names_hip[27] = \"parallax_pmdec_corr_Hip\"\n",
    "names_hip[28] = \"pmra_pmdec_corr_Hip\"\n",
    "names_hip[5] = \"Vmag_Hip\"\n",
    "names_hip[71] = \"HenryDraperId_Hip\"\n",
    "\n",
    "hipparcos = pd.read_csv(HIPTYC_DIR+\"hip_main.dat.gz\", usecols = names_hip.keys(), delimiter=\"|\", names = names_hip.values())\n",
    "hipparcos = pd.DataFrame(hipparcos)\n",
    "\n",
    "n1 = len(hipparcos)\n",
    "#hipparcos.apply(pd.to_numeric, errors=\"coerce\").info()                               # Convierte la información en tipo float\n",
    "\n",
    "hipparcos[\"ra_Hip\"] = pd.to_numeric(hipparcos[\"ra_Hip\"], errors=\"coerce\")             # Convierte en np.nan los valores no numer.\n",
    "hipparcos[\"dec_Hip\"] = pd.to_numeric(hipparcos[\"dec_Hip\"], errors=\"coerce\")           # Convierte en np.nan los valores no numer.\n",
    "hipparcos[\"parallax_Hip\"] = pd.to_numeric(hipparcos[\"parallax_Hip\"], errors=\"coerce\") # Convierte en np.nan los valores no numer.\n",
    "hipparcos.dropna(subset=[\"ra_Hip\", \"dec_Hip\", \"parallax_Hip\"], inplace=True)          # Elimina los registros con paralaje nulo\n",
    "\n",
    "n2 = len(hipparcos)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "len(hipparcos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TYCHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 22887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1035445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Información disponible en: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.13\n",
    "\n",
    "names_tyc={}\n",
    "names_tyc[1] = \"tycho2_id\"\n",
    "names_tyc[8] = \"ra_Tyc\"\n",
    "names_tyc[9] = \"dec_Tyc\"\n",
    "names_tyc[11] = \"parallax_Tyc\"\n",
    "names_tyc[12] = \"pmra_Tyc\"\n",
    "names_tyc[13] = \"pmdec_Tyc\"\n",
    "names_tyc[14] = \"ra_error_Tyc\"\n",
    "names_tyc[15] = \"dec_error_Tyc\"\n",
    "names_tyc[16] = \"parallax_error_Tyc\"\n",
    "names_tyc[17] = \"pmra_error_Tyc\"\n",
    "names_tyc[18] = \"pmdec_error_Tyc\"\n",
    "names_tyc[19] = \"ra_dec_corr_Tyc\"\n",
    "names_tyc[20] = \"ra_parallax_corr_Tyc\"\n",
    "names_tyc[21] = \"dec_parallax_corr_Tyc\"\n",
    "names_tyc[22] = \"ra_pmra_corr_Tyc\"\n",
    "names_tyc[23] = \"dec_pmra_corr_Tyc\"\n",
    "names_tyc[24] = \"parallax_pmra_corr_Tyc\"\n",
    "names_tyc[25] = \"ra_pmdec_corr_Tyc\"\n",
    "names_tyc[26] = \"dec_pmdec_corr_Tyc\"\n",
    "names_tyc[27] = \"parallax_pmdec_corr_Tyc\"\n",
    "names_tyc[28] = \"pmra_pmdec_corr_Tyc\"\n",
    "names_tyc[5] = \"Vmag_Tyc\"\n",
    "names_tyc[53] = \"HenryDraperId_Tyc\"\n",
    "\n",
    "tycho = pd.read_csv(HIPTYC_DIR+\"tyc_main.dat\", usecols = names_tyc.keys(), delimiter=\"|\", names = names_tyc.values())\n",
    "tycho = pd.DataFrame(tycho)\n",
    "\n",
    "# Dividir la cadena de texto en los 3 campos numéricos que componen el ID de Tycho_2 (separados por espacios en blanco)\n",
    "tycho[\"a\"], tycho[\"b\"], tycho[\"c\"] = tycho[\"tycho2_id\"].str.split().str\n",
    "\n",
    "# Concatenar los 3 campos numéricos que componen el ID de Tycho_2, separados por guión.\n",
    "tycho[\"tycho2_id\"] = tycho[\"a\"] + \"-\" + tycho[\"b\"] + \"-\" + tycho[\"c\"]\n",
    "\n",
    "# Borrar campos usados para la conversión\n",
    "del tycho[\"a\"], tycho[\"b\"], tycho[\"c\"]\n",
    "\n",
    "# Descartar elementos con paralajes nulos\n",
    "\n",
    "n1 = len(tycho)\n",
    "#tycho.apply(pd.to_numeric, errors=\"coerce\").info()                           # Convierte la información en tipo float\n",
    "\n",
    "tycho[\"ra_Tyc\"] = pd.to_numeric(tycho[\"ra_Tyc\"], errors=\"coerce\")             # Convierte en np.nan los valores no numéricos\n",
    "tycho[\"dec_Tyc\"] = pd.to_numeric(tycho[\"dec_Tyc\"], errors=\"coerce\")           # Convierte en np.nan los valores no numéricos\n",
    "tycho[\"parallax_Tyc\"] = pd.to_numeric(tycho[\"parallax_Tyc\"], errors=\"coerce\") # Convierte en np.nan los valores no numéricos\n",
    "tycho.dropna(subset=[\"ra_Tyc\", \"dec_Tyc\", \"parallax_Tyc\"], inplace=True)      # Elimina los registros con paralaje nulo\n",
    "\n",
    "n2 = len(tycho)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "len(tycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMBAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"typedident\",\"identifier\", \"radvel\", \"coord1(ICRS,J2000/2000)\", \"plx\", \"pm\", \"MagV\", \"spec.type\"]\n",
    "simbad = pd.read_csv(SIMBAD_DIR+\"simbad.csv\", usecols=cols, delimiter=\"|\")\n",
    "simbad = pd.DataFrame(simbad)\n",
    "\n",
    "# Modificación del ID del catálogo para que quede en formato INTEGER\n",
    "simbad[\"hip\"] = simbad[\"typedident\"].map(lambda x: str(x)[4:]).astype(float)\n",
    "del simbad[\"typedident\"]\n",
    "\n",
    "simbad[\"plx\"] = pd.to_numeric(simbad[\"plx\"], errors=\"coerce\")   \n",
    "\n",
    "# Cálculo de RA y DEC\n",
    "# 1. Eliminar espacios en blanco de los lados izquierdo y derecho de cada cadena de texto\n",
    "simbad[\"coord1(ICRS,J2000/2000)\"] = simbad[\"coord1(ICRS,J2000/2000)\"].str.strip()\n",
    "\n",
    "# 2. Dividir la cadena de texto en 6 campos (hh:mm:ss para RA y hh:mm:ss para DEC)\n",
    "simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"] = \\\n",
    "    simbad[\"coord1(ICRS,J2000/2000)\"].str.split(\" \").str\n",
    "\n",
    "# 3. Concatenar los 3 primeros campos mediante la fórmula de conversión de hh:mm:ss a grados para la ascensión recta\n",
    "simbad[\"ra_simbad\"] = simbad[\"ra_h\"].astype(float)*15 + simbad[\"ra_m\"].astype(float)/60 + simbad[\"ra_s\"].astype(float)/3600\n",
    "\n",
    "# 4. Concatenar los 3 últimos campos mediante la fórmula de conversión de hh:mm:ss a grados para la declinación\n",
    "simbad[\"dec_simbad\"] = np.sign(simbad[\"dec_h\"].astype(float)) * ( \\\n",
    "    np.abs(simbad[\"dec_h\"].astype(float)) + simbad[\"dec_m\"].astype(float)/60 + simbad[\"dec_s\"].astype(float)/3600 )\n",
    "\n",
    "# 5. Borrar campos usados para la conversión\n",
    "del simbad[\"coord1(ICRS,J2000/2000)\"]\n",
    "del simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"]\n",
    "\n",
    "# Cálculo del movimiento propio\n",
    "# 1. Eliminar espacios en blanco de los lados izquierdo y derecho de cada cadena de texto\n",
    "simbad[\"pm\"] = simbad[\"pm\"].str.strip()\n",
    "\n",
    "#2. Dividir la cadena de texto en 2 campos (PM_RA y PM_DEC)\n",
    "simbad[\"pmra_simbad\"], simbad[\"pmdec_simbad\"] = simbad[\"pm\"].str.split(\" \").str\n",
    "\n",
    "# 3. Borrar campos usados para la conversión\n",
    "del simbad[\"pm\"]\n",
    "\n",
    "# 4. Elimina los registros con paralaje nulo\n",
    "n1 = len(simbad)\n",
    "simbad.dropna(subset=[\"ra_simbad\", \"dec_simbad\", \"plx\"], inplace=True)      \n",
    "n2 = len(simbad)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "# Formato velocidad radial\n",
    "simbad[\"radvel\"] = simbad[\"radvel\"].str.strip()                   # Elimina espacios en blanco\n",
    "simbad[\"radvel\"] = simbad[\"radvel\"].replace(\"~\", np.nan)          # Reemplaza el caracter \"~\" por Null\n",
    "\n",
    "# Modificar nombre de algunas columnas\n",
    "simbad = simbad.rename(columns={\"identifier\": \"name_simbad\"})      # Modifica el nombre de la columna de nombres propios\n",
    "simbad = simbad.rename(columns={\"plx\": \"parallax_simbad\"})         # Modifca el nombre de la columna de paralajes\n",
    "simbad = simbad.rename(columns={\"spec.type\": \"sptype_simbad\"})     # Modifca el nombre de la columna de clasificación espectral\n",
    "simbad = simbad.rename(columns={\"radvel\": \"radial_vel_simbad\"})    # Modifica el nombre de la columna de velocidades radiales\n",
    "simbad = simbad.rename(columns={\"MagV\": \"Vmag_simbad\"})            # Modifica el nombre de la columna de magnitud V\n",
    "\n",
    "len(simbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RV Catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building catalogue Maldonado2010.tsv...\n",
      "Number of objects in Maldonado2010.tsv: 495\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 0.11\n",
      "Number of entries with zero error: 35\n",
      "Filtered catalogue: 473\n",
      "Building catalogue Web1995-HIP.csv...\n",
      "Number of objects in Web1995-HIP.csv: 494\n",
      "Number of objects in catalogue HIP: 494\n",
      "Median error: 1.7\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 494\n",
      "Building catalogue Web1995-TYC2.csv...\n",
      "Number of objects in Web1995-TYC2.csv: 673\n",
      "Number of objects in catalogue TYC2: 673\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 1.9\n",
      "Number of entries with zero error: 1\n",
      "Filtered catalogue: 673\n",
      "Building catalogue GCS2011.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects in GCS2011.tsv: 16682\n",
      "Number of objects in catalogue HIP: 14955\n",
      "Median error: 0.4\n",
      "Number of entries with zero error: 1678\n",
      "Filtered catalogue: 14139\n",
      "Building catalogue RAVE-DR5.tsv...\n",
      "Number of objects in RAVE-DR5.tsv: 520701\n",
      "Number of objects in catalogue TYCHO2: 309596\n",
      "Median error: 1.189\n",
      "Number of entries with zero error: 217\n",
      "Filtered catalogue: 520701\n",
      "Building catalogue Pulkovo.tsv...\n",
      "Number of objects in Pulkovo.tsv: 35493\n",
      "Number of objects in catalogue HIP: 35493\n",
      "Median error: 1.6\n",
      "Number of entries with zero error: 24715\n",
      "Filtered catalogue: 35493\n",
      "Building catalogue Famaey2005.tsv...\n",
      "Number of objects in Famaey2005.tsv: 6690\n",
      "Number of objects in catalogue HIP: 6690\n",
      "Median error: 0.22\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 6028\n",
      "Building catalogue BB2000.csv...\n",
      "Number of objects in BB2000.csv: 673\n",
      "Number of objects in catalogue TYC2: 673\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 1.9\n",
      "Number of entries with zero error: 1\n",
      "Filtered catalogue: 673\n",
      "Building catalogue Malaroda2012.csv...\n",
      "Number of objects in Malaroda2012.csv: 2178\n",
      "Number of objects in catalogue TYC2: 2178\n",
      "Number of objects in catalogue HIP: 866\n",
      "Median error: 1.0\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 2178\n",
      "Building catalogue Galah.tsv...\n",
      "Number of objects in Galah.tsv: 10680\n",
      "Number of objects in catalogue TYC2: 10680\n",
      "Median error: 0.6\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 10680\n",
      "Compiling final catalogue...\n",
      "Compiling final catalogue...\n",
      "Number of unfiltered entries: 591532\n",
      "Catalogues included: ['BB2000.csv' 'Famaey2005.tsv' 'GCS2011.tsv' 'Galah.tsv' 'Malaroda2012.csv'\n",
      " 'Maldonado2010.tsv' 'Pulkovo.tsv' 'RAVE-DR5.tsv' 'Web1995-HIP.csv'\n",
      " 'Web1995-TYC2.csv']\n",
      "Number of filtered entries: 590333\n",
      "Number of RV objects: 590333\n",
      "Number of total entries for hip: 56386\n",
      "Number of uniq entries for hip: 36867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:458: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total entries for tycho2_id: 322882\n",
      "Number of uniq entries for tycho2_id: 270658\n",
      "Total number of uniq objects:307525\n"
     ]
    }
   ],
   "source": [
    "data=dict()\n",
    "match=dict()\n",
    "RVcat=pd.DataFrame()\n",
    "srcdir=RV_DIR\n",
    "\n",
    "###################################################\n",
    "#READ CATALOGUES\n",
    "###################################################\n",
    "#MALDONADO2010\n",
    "name=\"Maldonado2010.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(82))+[83,84]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"]\n",
    "df[\"eRV\"]=data[name][\"e_RV\"]\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#WEB1995\n",
    "#III/213/catalog\n",
    "name=\"Web1995-HIP.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#WEB1995-TYC2\n",
    "#III/213/catalog\n",
    "name=\"Web1995-TYC2.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#GCS2011\n",
    "#J/A+A/530/A138/catalog\n",
    "name=\"GCS2011.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(174))+[175,176]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\"|\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#RAVE-DR5\n",
    "#III/279/rave_dr5\n",
    "name=\"RAVE-DR5.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(78))+[79,80]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['TYCHO2']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "data[name][\"TYC2\"]=data[name][\"TYCHO2\"]\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"RAJ2000\",DEJ2000=\"DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"HRV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_HRV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#PULKOVO\n",
    "#III/252/table8\n",
    "name=\"Pulkovo.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(61))+[62,63]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RA\",DEJ2000=\"_DE\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"eRV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#FAMAEY2005\n",
    "#J/A+A/430/165/tablea1\n",
    "name=\"Famaey2005.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(118))+[119,120]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#BB2000\n",
    "#III/213/catalogue\n",
    "name=\"BB2000.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#MALARODA2012\n",
    "#III/249/catalog\n",
    "name=\"Malaroda2012.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=1.0;df[\"eRV\"]=df[\"eRV\"].map(str) #TYPICAL VALUE FOR OTHER CATALOGUES\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#GALAH I\n",
    "#J/MNRAS/465/3203/catal\n",
    "name=\"Galah.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(54))+[55,56]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['TYC2']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"RAJ2000\",DEJ2000=\"DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=0.6;df[\"eRV\"]=df[\"eRV\"].map(str) #Martell et al. (2017)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "###################################################\n",
    "#COMPILING FULL TABLE\n",
    "###################################################\n",
    "print(\"Compiling final catalogue...\")\n",
    "RVcat=RVcat.rename(columns={'TYC2':'tycho2_id','HIP':'hip'})\n",
    "print(\"Compiling final catalogue...\")\n",
    "RVcatf=RVcat.reset_index(drop=True)\n",
    "print(\"Number of unfiltered entries:\",len(RVcatf))\n",
    "print(\"Catalogues included:\",np.unique(RVcat.CAT.values))\n",
    "RVcatf.is_copy=False\n",
    "cond=RVcatf.RV==''\n",
    "RVcatf=RVcatf.drop(RVcatf.index[cond])\n",
    "RVcatf.RV=RVcatf.RV.map(float)\n",
    "cond=RVcatf.eRV==''\n",
    "RVcatf=RVcatf.drop(RVcatf.index[cond])\n",
    "RVcatf.eRV=RVcatf.eRV.map(float)\n",
    "print(\"Number of filtered entries:\",len(RVcatf))\n",
    "\n",
    "RV=RVcatf\n",
    "cats=['hip','tycho2_id']\n",
    "for cname in cats:\n",
    "    RV[cname]=RV[cname].fillna('')\n",
    "    RV[cname]=RV[cname].map(str)\n",
    "dfstr=RV.select_dtypes(['object'])\n",
    "RV[dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "RV['hip']=RV['hip'].apply(lambda x:x.replace('.0',''))\n",
    "print(\"Number of RV objects: %d\"%len(RV))\n",
    "\n",
    "RVCat=pd.DataFrame()\n",
    "for col in \"hip\",\"tycho2_id\":\n",
    "    sel=RV[RV[col]!=''][[col,\"eRV\"]].sort_values([col,\"eRV\"])\n",
    "    print(\"Number of total entries for %s: %d\"%(col,len(sel)))\n",
    "    index=sel[col].drop_duplicates().index\n",
    "    uniq=RV.ix[index]\n",
    "    print(\"Number of uniq entries for %s: %d\"%(col,len(uniq)))\n",
    "    RVCat=RVCat.append(uniq)\n",
    "\n",
    "RVCat.to_csv(RV_DIR+\"RVCat.csv\",index=False)\n",
    "print(\"Total number of uniq objects:%d\"%len(RVCat))\n",
    "\n",
    "rv=RVCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAIA: 2057050\n",
      "HIPPARCOS: 117955\n",
      "TYCHO: 1035445\n",
      "SIMBAD: 118004\n",
      "RV: 307525\n"
     ]
    }
   ],
   "source": [
    "#Catalogs\n",
    "print(\"GAIA:\",len(gaia))\n",
    "print(\"HIPPARCOS:\",len(hipparcos))\n",
    "print(\"TYCHO:\",len(tycho))\n",
    "print(\"SIMBAD:\",len(simbad))\n",
    "print(\"RV:\",len(rv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging GAIA with RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging by tycho2_id...\n",
      "Number of matchings for tycho2_id: 210263\n",
      "Merging by hip...\n",
      "Number of matchings for hip: 25925\n",
      "Number of matches: 236188\n"
     ]
    }
   ],
   "source": [
    "cols=[\"tycho2_id\",\"hip\"]\n",
    "rvgaia=pd.DataFrame()\n",
    "for col in cols[::1],cols[::-1]:\n",
    "    print(\"Merging by %s...\"%col[0])\n",
    "    result=pd.merge(left=gaia[gaia[col[0]]!=''],\n",
    "                    right=rv[rv[col[0]]!=''],\n",
    "                    on=col[0])\n",
    "    result=result.drop(\"%s_y\"%col[1],1)\n",
    "    result=result.rename(columns={\"%s_x\"%col[1]:col[1]})\n",
    "    print(\"Number of matchings for %s: %d\"%(col[0],len(result)))\n",
    "    rvgaia=rvgaia.append(result)\n",
    "\n",
    "rvgaia=rvgaia.fillna('NULL')\n",
    "rvgaia.to_csv(RV_DIR+\"RVGaia.csv\",index=False)\n",
    "print(\"Number of matches: %d\"%len(rvgaia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hip', 'tycho2_id', 'ra', 'ra_error', 'dec', 'dec_error', 'parallax',\n",
       "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
       "       'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr',\n",
       "       'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
       "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',\n",
       "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_g_mean_mag', 'l',\n",
       "       'b', 'ecl_lon', 'ecl_lat', 'DEJ2000', 'RAJ2000', 'RV', 'eRV', 'CAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvgaia.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
