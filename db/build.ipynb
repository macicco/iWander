{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build AstroRV Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed to build the AstroRV catalog, a complete compilation of astrometric and radial velocities information of nearby stars. \n",
    "\n",
    "This catalog was originally aimed at studying the interstellar origin probability for objects approaching the Solar System in unbound orbits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAIA SOURCES\n",
    "TGAS_DIR=\"DataGAIA/Data-Gaia/\"\n",
    "\n",
    "#SIMBAD SOURCES\n",
    "SIMBAD_DIR=\"DataGAIA/Data-Simbad/\"\n",
    "\n",
    "#TYCHO2/HIPPARCOS SOURCES\n",
    "HIPTYC_DIR=\"DataGAIA/Data-Hipparcos/\"\n",
    "\n",
    "#RADIAL VELOCITY SOURCES\n",
    "RV_DIR=\"RVGaia/RV/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-000.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-001.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-002.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-003.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-004.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-005.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-006.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-007.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-008.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-009.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-010.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-011.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-012.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-013.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-014.csv.gz\n",
      "Reading DataGAIA/Data-Gaia/TgasSource_000-000-015.csv.gz\n",
      "Gaia: Subset Hipparcos: 93635\n",
      "Gaia: Subset Tycho-2: 1963415\n",
      "Total Gaia: 2057050\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LECTURA DE ARCHIVOS DE GAIA\n",
    "# =============================================================================\n",
    "\n",
    "# Description:\n",
    "\n",
    "# hip : Hipparcos identifier (int).\n",
    "# tycho2_id : Tycho 2 identifier (string).\n",
    "# ref_epoch : Reference epoch (double, Time[Julian Years]), expressed as a Julian Year in TCB.\n",
    "# ra : Right ascension (double, Angle[deg]). Barycentric right ascension of the source in ICRS.\n",
    "# ra error : Standard error of right ascension (double, Angle[mas]).\n",
    "# dec : Declination (double, Angle[deg]). Barycentric declination of the source in ICRS.\n",
    "# dec error : Standard error of declination (double, Angle[mas]).\n",
    "# parallax : Parallax (double, Angle[mas]). Absolute barycentric stellar parallax of the source.\n",
    "# parallax error : Standard error of parallax (double, Angle[mas]).\n",
    "# pmra : Proper motion in right ascension direction (double, Angular Velocity[mas/year].\n",
    "# pmra error : Standard error of proper motion in right ascension direction (double, Angular Velocity[mas/year]).\n",
    "# pmdec : Proper motion in declination direction (double, Angular Velocity[mas/year].\n",
    "# pmdec error : Standard error of proper motion in declination direction (double, Angular Velocity[mas/year]).\n",
    "# phot g mean mag : G-band mean magnitude (double, Magnitude[mag]) Mean magnitude in the G band.\n",
    "# l : Galactic longitude (double, Angle[deg]).\n",
    "# b : Galactic latitude (double, Angle[deg]).\n",
    "\n",
    "cols_gaia = [\"hip\", \"tycho2_id\", \"ra\", \"ra_error\", \"dec\", \"dec_error\", \"parallax\", \"parallax_error\", \"pmra\", \"pmra_error\", \\\n",
    "        \"pmdec\", \"pmdec_error\", \"ra_dec_corr\", \"ra_parallax_corr\", \"ra_pmra_corr\", \"ra_pmdec_corr\", \"dec_parallax_corr\", \\\n",
    "        \"dec_pmra_corr\", \"dec_pmdec_corr\", \"parallax_pmra_corr\", \"parallax_pmdec_corr\", \"pmra_pmdec_corr\", \\\n",
    "        \"phot_g_mean_flux\", \"phot_g_mean_flux_error\", \"phot_g_mean_mag\", \"l\", \"b\", \"ecl_lon\", \"ecl_lat\"]\n",
    "\n",
    "for i in range(16):\n",
    "    filename = TGAS_DIR + \"TgasSource_000-000-0\" + str(i).zfill(2) + \".csv.gz\"\n",
    "    if i == 0:\n",
    "        print(\"Reading\", filename)\n",
    "        gaia = pd.read_csv(filename, usecols=cols_gaia)\n",
    "    else:\n",
    "        print(\"Reading\", filename)\n",
    "        DRx = pd.read_csv(filename, usecols=cols_gaia)\n",
    "        gaia = gaia.append(DRx)\n",
    "\n",
    "gaia = pd.DataFrame(gaia)\n",
    "\n",
    "gaia_hip = gaia[gaia.hip.notnull()]\n",
    "gaia_tyc = gaia[gaia.tycho2_id.notnull()]\n",
    "\n",
    "print(\"Gaia: Subset Hipparcos:\", len(gaia_hip))\n",
    "print(\"Gaia: Subset Tycho-2:\", len(gaia_tyc))\n",
    "print(\"Total Gaia:\", len(gaia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIPPARCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117955"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Información disponible en: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.1\n",
    "names_hip=OrderedDict({})\n",
    "names_hip[1] = \"hip\"\n",
    "names_hip[8] = \"ra_Hip\"\n",
    "names_hip[9] = \"dec_Hip\"\n",
    "names_hip[11] = \"parallax_Hip\"\n",
    "names_hip[12] = \"pmra_Hip\"\n",
    "names_hip[13] = \"pmdec_Hip\"\n",
    "names_hip[14] = \"ra_error_Hip\"\n",
    "names_hip[15] = \"dec_error_Hip\"\n",
    "names_hip[16] = \"parallax_error_Hip\"\n",
    "names_hip[17] = \"pmra_error_Hip\"\n",
    "names_hip[18] = \"pmdec_error_Hip\"\n",
    "names_hip[19] = \"ra_dec_corr_Hip\"\n",
    "names_hip[20] = \"ra_parallax_corr_Hip\"\n",
    "names_hip[21] = \"dec_parallax_corr_Hip\"\n",
    "names_hip[22] = \"ra_pmra_corr_Hip\"\n",
    "names_hip[23] = \"dec_pmra_corr_Hip\"\n",
    "names_hip[24] = \"parallax_pmra_corr_Hip\"\n",
    "names_hip[25] = \"ra_pmdec_corr_Hip\"\n",
    "names_hip[26] = \"dec_pmdec_corr_Hip\"\n",
    "names_hip[27] = \"parallax_pmdec_corr_Hip\"\n",
    "names_hip[28] = \"pmra_pmdec_corr_Hip\"\n",
    "names_hip[5] = \"Vmag_Hip\"\n",
    "names_hip[71] = \"HenryDraperId_Hip\"\n",
    "\n",
    "hipparcos = pd.read_csv(HIPTYC_DIR+\"hip_main.dat.gz\", usecols = names_hip.keys(), delimiter=\"|\", names = names_hip.values())\n",
    "hipparcos = pd.DataFrame(hipparcos)\n",
    "\n",
    "n1 = len(hipparcos)\n",
    "#hipparcos.apply(pd.to_numeric, errors=\"coerce\").info()                               # Convierte la información en tipo float\n",
    "\n",
    "hipparcos[\"ra_Hip\"] = pd.to_numeric(hipparcos[\"ra_Hip\"], errors=\"coerce\")             # Convierte en np.nan los valores no numer.\n",
    "hipparcos[\"dec_Hip\"] = pd.to_numeric(hipparcos[\"dec_Hip\"], errors=\"coerce\")           # Convierte en np.nan los valores no numer.\n",
    "hipparcos[\"parallax_Hip\"] = pd.to_numeric(hipparcos[\"parallax_Hip\"], errors=\"coerce\") # Convierte en np.nan los valores no numer.\n",
    "hipparcos.dropna(subset=[\"ra_Hip\", \"dec_Hip\", \"parallax_Hip\"], inplace=True)          # Elimina los registros con paralaje nulo\n",
    "\n",
    "n2 = len(hipparcos)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "len(hipparcos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_values(['hip', 'ra_Hip', 'dec_Hip', 'parallax_Hip', 'pmra_Hip', 'pmdec_Hip', 'ra_error_Hip', 'dec_error_Hip', 'parallax_error_Hip', 'pmra_error_Hip', 'pmdec_error_Hip', 'ra_dec_corr_Hip', 'ra_parallax_corr_Hip', 'dec_parallax_corr_Hip', 'ra_pmra_corr_Hip', 'dec_pmra_corr_Hip', 'parallax_pmra_corr_Hip', 'ra_pmdec_corr_Hip', 'dec_pmdec_corr_Hip', 'parallax_pmdec_corr_Hip', 'pmra_pmdec_corr_Hip', 'Vmag_Hip', 'HenryDraperId_Hip'])\n"
     ]
    }
   ],
   "source": [
    "print(names_hip.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TYCHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 22887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1035445"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Información disponible en: http://cdsarc.u-strasbg.fr/viz-bin/Cat?cat=I%2F239&target=readme&#sRM2.13\n",
    "\n",
    "names_tyc={}\n",
    "names_tyc[1] = \"tycho2_id\"\n",
    "names_tyc[8] = \"ra_Tyc\"\n",
    "names_tyc[9] = \"dec_Tyc\"\n",
    "names_tyc[11] = \"parallax_Tyc\"\n",
    "names_tyc[12] = \"pmra_Tyc\"\n",
    "names_tyc[13] = \"pmdec_Tyc\"\n",
    "names_tyc[14] = \"ra_error_Tyc\"\n",
    "names_tyc[15] = \"dec_error_Tyc\"\n",
    "names_tyc[16] = \"parallax_error_Tyc\"\n",
    "names_tyc[17] = \"pmra_error_Tyc\"\n",
    "names_tyc[18] = \"pmdec_error_Tyc\"\n",
    "names_tyc[19] = \"ra_dec_corr_Tyc\"\n",
    "names_tyc[20] = \"ra_parallax_corr_Tyc\"\n",
    "names_tyc[21] = \"dec_parallax_corr_Tyc\"\n",
    "names_tyc[22] = \"ra_pmra_corr_Tyc\"\n",
    "names_tyc[23] = \"dec_pmra_corr_Tyc\"\n",
    "names_tyc[24] = \"parallax_pmra_corr_Tyc\"\n",
    "names_tyc[25] = \"ra_pmdec_corr_Tyc\"\n",
    "names_tyc[26] = \"dec_pmdec_corr_Tyc\"\n",
    "names_tyc[27] = \"parallax_pmdec_corr_Tyc\"\n",
    "names_tyc[28] = \"pmra_pmdec_corr_Tyc\"\n",
    "names_tyc[5] = \"Vmag_Tyc\"\n",
    "names_tyc[53] = \"HenryDraperId_Tyc\"\n",
    "\n",
    "tycho = pd.read_csv(HIPTYC_DIR+\"tyc_main.dat\", usecols = list(names_tyc.keys()), delimiter=\"|\", names = names_tyc.values())\n",
    "tycho = pd.DataFrame(tycho)\n",
    "\n",
    "# Dividir la cadena de texto en los 3 campos numéricos que componen el ID de Tycho_2 (separados por espacios en blanco)\n",
    "tycho[\"a\"], tycho[\"b\"], tycho[\"c\"] = tycho[\"tycho2_id\"].str.split().str\n",
    "\n",
    "# Concatenar los 3 campos numéricos que componen el ID de Tycho_2, separados por guión.\n",
    "tycho[\"tycho2_id\"] = tycho[\"a\"] + \"-\" + tycho[\"b\"] + \"-\" + tycho[\"c\"]\n",
    "\n",
    "# Borrar campos usados para la conversión\n",
    "del tycho[\"a\"], tycho[\"b\"], tycho[\"c\"]\n",
    "\n",
    "# Descartar elementos con paralajes nulos\n",
    "\n",
    "n1 = len(tycho)\n",
    "#tycho.apply(pd.to_numeric, errors=\"coerce\").info()                           # Convierte la información en tipo float\n",
    "\n",
    "tycho[\"ra_Tyc\"] = pd.to_numeric(tycho[\"ra_Tyc\"], errors=\"coerce\")             # Convierte en np.nan los valores no numéricos\n",
    "tycho[\"dec_Tyc\"] = pd.to_numeric(tycho[\"dec_Tyc\"], errors=\"coerce\")           # Convierte en np.nan los valores no numéricos\n",
    "tycho[\"parallax_Tyc\"] = pd.to_numeric(tycho[\"parallax_Tyc\"], errors=\"coerce\") # Convierte en np.nan los valores no numéricos\n",
    "tycho.dropna(subset=[\"ra_Tyc\", \"dec_Tyc\", \"parallax_Tyc\"], inplace=True)      # Elimina los registros con paralaje nulo\n",
    "\n",
    "n2 = len(tycho)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "len(tycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMBAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects discarded: 175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "118004"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"typedident\",\"identifier\", \"radvel\", \"coord1(ICRS,J2000/2000)\", \"plx\", \"pm\", \"MagV\", \"spec.type\"]\n",
    "simbad = pd.read_csv(SIMBAD_DIR+\"simbad.csv\", usecols=cols, delimiter=\"|\")\n",
    "simbad = pd.DataFrame(simbad)\n",
    "\n",
    "# Modificación del ID del catálogo para que quede en formato INTEGER\n",
    "simbad[\"hip\"] = simbad[\"typedident\"].map(lambda x: str(x)[4:]).astype(float)\n",
    "del simbad[\"typedident\"]\n",
    "\n",
    "simbad[\"plx\"] = pd.to_numeric(simbad[\"plx\"], errors=\"coerce\")   \n",
    "\n",
    "# Cálculo de RA y DEC\n",
    "# 1. Eliminar espacios en blanco de los lados izquierdo y derecho de cada cadena de texto\n",
    "simbad[\"coord1(ICRS,J2000/2000)\"] = simbad[\"coord1(ICRS,J2000/2000)\"].str.strip()\n",
    "\n",
    "# 2. Dividir la cadena de texto en 6 campos (hh:mm:ss para RA y hh:mm:ss para DEC)\n",
    "simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"] = \\\n",
    "    simbad[\"coord1(ICRS,J2000/2000)\"].str.split(\" \").str\n",
    "\n",
    "# 3. Concatenar los 3 primeros campos mediante la fórmula de conversión de hh:mm:ss a grados para la ascensión recta\n",
    "simbad[\"ra_simbad\"] = simbad[\"ra_h\"].astype(float)*15 + simbad[\"ra_m\"].astype(float)/60 + simbad[\"ra_s\"].astype(float)/3600\n",
    "\n",
    "# 4. Concatenar los 3 últimos campos mediante la fórmula de conversión de hh:mm:ss a grados para la declinación\n",
    "simbad[\"dec_simbad\"] = np.sign(simbad[\"dec_h\"].astype(float)) * ( \\\n",
    "    np.abs(simbad[\"dec_h\"].astype(float)) + simbad[\"dec_m\"].astype(float)/60 + simbad[\"dec_s\"].astype(float)/3600 )\n",
    "\n",
    "# 5. Borrar campos usados para la conversión\n",
    "del simbad[\"coord1(ICRS,J2000/2000)\"]\n",
    "del simbad[\"ra_h\"], simbad[\"ra_m\"], simbad[\"ra_s\"], simbad[\"dec_h\"], simbad[\"dec_m\"], simbad[\"dec_s\"]\n",
    "\n",
    "# Cálculo del movimiento propio\n",
    "# 1. Eliminar espacios en blanco de los lados izquierdo y derecho de cada cadena de texto\n",
    "simbad[\"pm\"] = simbad[\"pm\"].str.strip()\n",
    "\n",
    "#2. Dividir la cadena de texto en 2 campos (PM_RA y PM_DEC)\n",
    "simbad[\"pmra_simbad\"], simbad[\"pmdec_simbad\"] = simbad[\"pm\"].str.split(\" \").str\n",
    "\n",
    "# 3. Borrar campos usados para la conversión\n",
    "del simbad[\"pm\"]\n",
    "\n",
    "# 4. Elimina los registros con paralaje nulo\n",
    "n1 = len(simbad)\n",
    "simbad.dropna(subset=[\"ra_simbad\", \"dec_simbad\", \"plx\"], inplace=True)      \n",
    "n2 = len(simbad)\n",
    "print(\"Objects discarded:\", n1-n2)\n",
    "\n",
    "# Formato velocidad radial\n",
    "simbad[\"radvel\"] = simbad[\"radvel\"].str.strip()                   # Elimina espacios en blanco\n",
    "simbad[\"radvel\"] = simbad[\"radvel\"].replace(\"~\", np.nan)          # Reemplaza el caracter \"~\" por Null\n",
    "\n",
    "# Modificar nombre de algunas columnas\n",
    "simbad = simbad.rename(columns={\"identifier\": \"name_simbad\"})      # Modifica el nombre de la columna de nombres propios\n",
    "simbad = simbad.rename(columns={\"plx\": \"parallax_simbad\"})         # Modifca el nombre de la columna de paralajes\n",
    "simbad = simbad.rename(columns={\"spec.type\": \"sptype_simbad\"})     # Modifca el nombre de la columna de clasificación espectral\n",
    "simbad = simbad.rename(columns={\"radvel\": \"radial_vel_simbad\"})    # Modifica el nombre de la columna de velocidades radiales\n",
    "simbad = simbad.rename(columns={\"MagV\": \"Vmag_simbad\"})            # Modifica el nombre de la columna de magnitud V\n",
    "\n",
    "len(simbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RV Catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building catalogue Maldonado2010.tsv...\n",
      "Number of objects in Maldonado2010.tsv: 495\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 0.11\n",
      "Number of entries with zero error: 35\n",
      "Filtered catalogue: 473\n",
      "Building catalogue Web1995-HIP.csv...\n",
      "Number of objects in Web1995-HIP.csv: 494\n",
      "Number of objects in catalogue HIP: 494\n",
      "Median error: 1.7\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 494\n",
      "Building catalogue Web1995-TYC2.csv...\n",
      "Number of objects in Web1995-TYC2.csv: 673\n",
      "Number of objects in catalogue TYC2: 673\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 1.9\n",
      "Number of entries with zero error: 1\n",
      "Filtered catalogue: 673\n",
      "Building catalogue GCS2011.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects in GCS2011.tsv: 16682\n",
      "Number of objects in catalogue HIP: 14955\n",
      "Median error: 0.4\n",
      "Number of entries with zero error: 1678\n",
      "Filtered catalogue: 14139\n",
      "Building catalogue RAVE-DR5.tsv...\n",
      "Number of objects in RAVE-DR5.tsv: 520701\n",
      "Number of objects in catalogue TYCHO2: 309596\n",
      "Median error: 1.189\n",
      "Number of entries with zero error: 217\n",
      "Filtered catalogue: 520701\n",
      "Building catalogue Pulkovo.tsv...\n",
      "Number of objects in Pulkovo.tsv: 35493\n",
      "Number of objects in catalogue HIP: 35493\n",
      "Median error: 1.6\n",
      "Number of entries with zero error: 24715\n",
      "Filtered catalogue: 35493\n",
      "Building catalogue Famaey2005.tsv...\n",
      "Number of objects in Famaey2005.tsv: 6690\n",
      "Number of objects in catalogue HIP: 6690\n",
      "Median error: 0.22\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 6028\n",
      "Building catalogue BB2000.csv...\n",
      "Number of objects in BB2000.csv: 673\n",
      "Number of objects in catalogue TYC2: 673\n",
      "Number of objects in catalogue HIP: 495\n",
      "Median error: 1.9\n",
      "Number of entries with zero error: 1\n",
      "Filtered catalogue: 673\n",
      "Building catalogue Malaroda2012.csv...\n",
      "Number of objects in Malaroda2012.csv: 2178\n",
      "Number of objects in catalogue TYC2: 2178\n",
      "Number of objects in catalogue HIP: 866\n",
      "Median error: 1.0\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 2178\n",
      "Building catalogue Galah.tsv...\n",
      "Number of objects in Galah.tsv: 10680\n",
      "Number of objects in catalogue TYC2: 10680\n",
      "Median error: 0.6\n",
      "Number of entries with zero error: 0\n",
      "Filtered catalogue: 10680\n",
      "Compiling final catalogue...\n",
      "Compiling final catalogue...\n",
      "Number of unfiltered entries: 591532\n",
      "Catalogues included: ['BB2000.csv' 'Famaey2005.tsv' 'GCS2011.tsv' 'Galah.tsv' 'Malaroda2012.csv'\n",
      " 'Maldonado2010.tsv' 'Pulkovo.tsv' 'RAVE-DR5.tsv' 'Web1995-HIP.csv'\n",
      " 'Web1995-TYC2.csv']\n",
      "Number of filtered entries: 590333\n",
      "Number of RV objects: 590333\n",
      "Number of total entries for hip: 56386\n",
      "Number of uniq entries for hip: 36867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:459: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total entries for tycho2_id: 322882\n",
      "Number of uniq entries for tycho2_id: 270658\n",
      "Total number of uniq objects:307525\n"
     ]
    }
   ],
   "source": [
    "data=dict()\n",
    "match=dict()\n",
    "RVcat=pd.DataFrame()\n",
    "srcdir=RV_DIR\n",
    "\n",
    "###################################################\n",
    "#READ CATALOGUES\n",
    "###################################################\n",
    "#MALDONADO2010\n",
    "#J/A+A/521/A12/table1\n",
    "name=\"Maldonado2010.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(82))+[83,84]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"]\n",
    "df[\"eRV\"]=data[name][\"e_RV\"]\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#WEB1995\n",
    "#III/213/catalog\n",
    "name=\"Web1995-HIP.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#WEB1995-TYC2\n",
    "#III/213/catalog\n",
    "name=\"Web1995-TYC2.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#GCS2011\n",
    "#J/A+A/530/A138/catalog\n",
    "name=\"GCS2011.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(174))+[175,176]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\"|\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#RAVE-DR5\n",
    "#III/279/rave_dr5\n",
    "name=\"RAVE-DR5.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(78))+[79,80]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['TYCHO2']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "data[name][\"TYC2\"]=data[name][\"TYCHO2\"]\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"RAJ2000\",DEJ2000=\"DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"HRV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_HRV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#PULKOVO\n",
    "#III/252/table8\n",
    "name=\"Pulkovo.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(61))+[62,63]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RA\",DEJ2000=\"_DE\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"eRV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#FAMAEY2005\n",
    "#J/A+A/430/165/tablea1\n",
    "name=\"Famaey2005.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(118))+[119,120]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#BB2000\n",
    "#III/213/catalogue\n",
    "name=\"BB2000.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=data[name][\"e_RV\"].map(str)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#MALARODA2012\n",
    "#III/249/catalog\n",
    "name=\"Malaroda2012.csv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "data[name]=pd.read_csv(srcdir+name)\n",
    "cats=['TYC2','HIP']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"_RAJ2000\",DEJ2000=\"_DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=1.0;df[\"eRV\"]=df[\"eRV\"].map(str) #TYPICAL VALUE FOR OTHER CATALOGUES\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "#GALAH I\n",
    "#J/MNRAS/465/3203/catal\n",
    "name=\"Galah.tsv\"\n",
    "print(\"Building catalogue %s...\"%name)\n",
    "comments=list(range(54))+[55,56]\n",
    "data[name]=pd.read_csv(srcdir+name,sep=\";\",skiprows=comments)\n",
    "cats=['TYC2']\n",
    "for cname in cats:\n",
    "    data[name][cname]=data[name][cname].fillna('')\n",
    "    data[name][cname]=data[name][cname].map(str)\n",
    "dfstr=data[name].select_dtypes(['object'])\n",
    "data[name][dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "print(\"Number of objects in %s:\"%name,len(data[name]))\n",
    "for cat in cats:\n",
    "    cond=data[name][cat]!=''\n",
    "    print(\"Number of objects in catalogue %s:\"%cat,len(data[name][cat][cond]))\n",
    "#STORING RESULTS\n",
    "df=pd.DataFrame()\n",
    "if not 'TYC2' in data[name].columns:df[\"TYC2\"]=''\n",
    "else:df[\"TYC2\"]=data[name][\"TYC2\"]\n",
    "if not 'HIP' in data[name].columns:df[\"HIP\"]=''\n",
    "else:df[\"HIP\"]=data[name][\"HIP\"].apply(lambda x:x.replace('.0',''))\n",
    "COORDS=dict(RAJ2000=\"RAJ2000\",DEJ2000=\"DEJ2000\")\n",
    "for C in COORDS.keys():df[C]=data[name][COORDS[C]]\n",
    "df[\"RV\"]=data[name][\"RV\"].map(str)\n",
    "df[\"eRV\"]=0.6;df[\"eRV\"]=df[\"eRV\"].map(str) #Martell et al. (2017)\n",
    "df[\"CAT\"]=name\n",
    "#ZERO ERRORS\n",
    "cond=df.RV==''\n",
    "df=df.drop(df.index[cond])\n",
    "df.RV=df.RV.map(float)\n",
    "df.eRV[df.eRV=='']=0.0\n",
    "df.eRV=df.eRV.map(float)\n",
    "med=df.eRV[df.eRV>0].median()\n",
    "print(\"Median error:\",med)\n",
    "print(\"Number of entries with zero error:\",len(df.eRV[df.eRV==0]))\n",
    "df.eRV[df.eRV==0]=med\n",
    "#RESULTING SIZE\n",
    "print(\"Filtered catalogue:\",len(df))\n",
    "#FILLNA\n",
    "RVcat=RVcat.append(df.fillna(''))\n",
    "\n",
    "###################################################\n",
    "#COMPILING FULL TABLE\n",
    "###################################################\n",
    "print(\"Compiling final catalogue...\")\n",
    "RVcat=RVcat.rename(columns={'TYC2':'tycho2_id','HIP':'hip'})\n",
    "print(\"Compiling final catalogue...\")\n",
    "RVcatf=RVcat.reset_index(drop=True)\n",
    "print(\"Number of unfiltered entries:\",len(RVcatf))\n",
    "print(\"Catalogues included:\",np.unique(RVcat.CAT.values))\n",
    "RVcatf.is_copy=False\n",
    "cond=RVcatf.RV==''\n",
    "RVcatf=RVcatf.drop(RVcatf.index[cond])\n",
    "RVcatf.RV=RVcatf.RV.map(float)\n",
    "cond=RVcatf.eRV==''\n",
    "RVcatf=RVcatf.drop(RVcatf.index[cond])\n",
    "RVcatf.eRV=RVcatf.eRV.map(float)\n",
    "print(\"Number of filtered entries:\",len(RVcatf))\n",
    "\n",
    "RV=RVcatf\n",
    "cats=['hip','tycho2_id']\n",
    "for cname in cats:\n",
    "    RV[cname]=RV[cname].fillna('')\n",
    "    RV[cname]=RV[cname].map(str)\n",
    "dfstr=RV.select_dtypes(['object'])\n",
    "RV[dfstr.columns]=dfstr.apply(lambda x: x.str.strip())\n",
    "RV['hip']=RV['hip'].apply(lambda x:x.replace('.0',''))\n",
    "print(\"Number of RV objects: %d\"%len(RV))\n",
    "\n",
    "RVCat=pd.DataFrame()\n",
    "for col in \"hip\",\"tycho2_id\":\n",
    "    sel=RV[RV[col]!=''][[col,\"eRV\"]].sort_values([col,\"eRV\"])\n",
    "    print(\"Number of total entries for %s: %d\"%(col,len(sel)))\n",
    "    index=sel[col].drop_duplicates().index\n",
    "    uniq=RV.ix[index]\n",
    "    print(\"Number of uniq entries for %s: %d\"%(col,len(uniq)))\n",
    "    RVCat=RVCat.append(uniq)\n",
    "\n",
    "RVCat.to_csv(RV_DIR+\"RVCat.csv\",index=False)\n",
    "print(\"Total number of uniq objects:%d\"%len(RVCat))\n",
    "\n",
    "rv=RVCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAIA: 2057050\n",
      "HIPPARCOS: 117955\n",
      "TYCHO: 1035445\n",
      "SIMBAD: 118004\n",
      "RV: 307525\n"
     ]
    }
   ],
   "source": [
    "#Catalogs\n",
    "print(\"GAIA:\",len(gaia))\n",
    "print(\"HIPPARCOS:\",len(hipparcos))\n",
    "print(\"TYCHO:\",len(tycho))\n",
    "print(\"SIMBAD:\",len(simbad))\n",
    "print(\"RV:\",len(rv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Astro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aporte Hipparcos: 24320\n",
      "Aporte Tycho: 259824\n",
      "Aporte Simbad: 67\n",
      "Tamaño total: 2341261\n"
     ]
    }
   ],
   "source": [
    "# db = Gaia + Hipparcos\n",
    "gaia[\"source\"] = \"gaia\"\n",
    "exclusive_hip = hipparcos[~hipparcos.hip.isin(gaia_hip.hip)]\n",
    "exclusive_hip.rename(columns=lambda x: x.replace(\"_Hip\", \"\"), inplace=True)\n",
    "exclusive_hip[\"source\"] = \"hipparcos\"\n",
    "db = pd.concat([gaia, exclusive_hip], axis=0)\n",
    "print(\"Aporte Hipparcos:\", len(exclusive_hip))\n",
    "\n",
    "# db = db + Tycho\n",
    "exclusive_tyc = tycho[~tycho.tycho2_id.isin(gaia_tyc.tycho2_id)]\n",
    "exclusive_tyc.rename(columns=lambda x: x.replace(\"_Tyc\", \"\"), inplace=True)\n",
    "exclusive_tyc[\"source\"] = \"tycho\"\n",
    "db = pd.concat([db, exclusive_tyc], axis=0)\n",
    "print(\"Aporte Tycho:\", len(exclusive_tyc))\n",
    "\n",
    "# db = db + Simbad\n",
    "exclusive_simbad = simbad[~simbad.hip.isin(db.hip)]\n",
    "exclusive_simbad.rename(columns=lambda x: x.replace(\"_simbad\", \"\"), inplace=True)\n",
    "exclusive_simbad = exclusive_simbad.loc[:,[\"hip\", \"ra\", \"dec\", \"parallax\", \"pmra\", \"pmdec\"]]\n",
    "exclusive_simbad[\"source\"] = \"simbad\"\n",
    "db = pd.concat([db, exclusive_simbad], axis=0)\n",
    "print(\"Aporte Simbad:\", len(exclusive_simbad))\n",
    "\n",
    "# db = db + todos los elementos de Simbad [nombre_star, tipo_espectral, velocidad_radial, Vmag]\n",
    "db = db.merge(simbad.loc[:,[\"hip\", \"name_simbad\",\"sptype_simbad\",\"radial_vel_simbad\",\"Vmag_simbad\"]], \\\n",
    "              left_on=\"hip\", right_on=\"hip\", how=\"left\")\n",
    "\n",
    "# Organizar columnas\n",
    "cols = [\"source\"] + cols_gaia + [\"Vmag\",\"HenryDraperId\"] + [\"name_simbad\",\"sptype_simbad\",\"radial_vel_simbad\",\"Vmag_simbad\"]\n",
    "db = db[cols]\n",
    "db = db.reset_index(drop=True)\n",
    "\n",
    "# Resultado\n",
    "print(\"Tamaño total:\", len(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Astro Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño inicial de la base de datos alimentada con Gaia: 2057050\n",
      "Tamaño de Hipparcos: 117955 Tamaño final de la base de datos maestra: 2081370 . Aporte: 24320\n",
      "Tamaño de Tycho: 1035445 Tamaño final de la base de datos maestra: 2341194 . Aporte: 259824\n",
      "Tamaño de Simbad: 118004 Tamaño final de la base de datos maestra: 2341261 . Aporte: 67\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREACIÓN BASE DE DATOS COMPLETA CON TODOS LOS ATRIBUTOS DE LAS OTRAS BASES DE DATOS\n",
    "# =============================================================================\n",
    "\n",
    "n1 = len(gaia)\n",
    "print(\"Tamaño inicial de la base de datos alimentada con Gaia:\", n1)\n",
    "\n",
    "database = gaia.merge(hipparcos, left_on=\"hip\", right_on=\"hip\", how=\"outer\")\n",
    "n2 = len(database)\n",
    "print(\"Tamaño de Hipparcos:\", len(hipparcos), \"Tamaño final de la base de datos maestra:\", n2, \". Aporte:\", n2-n1)\n",
    "\n",
    "database = database.merge(tycho, left_on=\"tycho2_id\", right_on=\"tycho2_id\", how=\"outer\")\n",
    "n3 = len(database)\n",
    "print(\"Tamaño de Tycho:\", len(tycho), \"Tamaño final de la base de datos maestra:\", n3, \". Aporte:\", n3-n2)\n",
    "\n",
    "database = database.merge(simbad, left_on=\"hip\", right_on=\"hip\", how=\"outer\")\n",
    "n4 = len(database)\n",
    "print(\"Tamaño de Simbad:\", len(simbad), \"Tamaño final de la base de datos maestra:\", n4, \". Aporte:\", n4-n3)\n",
    "\n",
    "database = database.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hip', 'tycho2_id', 'ra', 'ra_error', 'dec', 'dec_error', 'parallax',\n",
       "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
       "       'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr',\n",
       "       'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
       "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',\n",
       "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_g_mean_mag', 'l',\n",
       "       'b', 'ecl_lon', 'ecl_lat', 'source', 'Vmag_Hip', 'HenryDraperId_Hip',\n",
       "       'ra_Hip', 'dec_Hip', 'parallax_Hip', 'pmra_Hip', 'pmdec_Hip',\n",
       "       'ra_error_Hip', 'dec_error_Hip', 'parallax_error_Hip', 'pmra_error_Hip',\n",
       "       'pmdec_error_Hip', 'ra_dec_corr_Hip', 'ra_parallax_corr_Hip',\n",
       "       'dec_parallax_corr_Hip', 'ra_pmra_corr_Hip', 'dec_pmra_corr_Hip',\n",
       "       'parallax_pmra_corr_Hip', 'ra_pmdec_corr_Hip', 'dec_pmdec_corr_Hip',\n",
       "       'parallax_pmdec_corr_Hip', 'pmra_pmdec_corr_Hip', 'Vmag_Tyc', 'ra_Tyc',\n",
       "       'dec_Tyc', 'parallax_Tyc', 'pmra_Tyc', 'pmdec_Tyc', 'ra_error_Tyc',\n",
       "       'dec_error_Tyc', 'parallax_error_Tyc', 'pmra_error_Tyc',\n",
       "       'pmdec_error_Tyc', 'ra_dec_corr_Tyc', 'ra_parallax_corr_Tyc',\n",
       "       'dec_parallax_corr_Tyc', 'ra_pmra_corr_Tyc', 'dec_pmra_corr_Tyc',\n",
       "       'parallax_pmra_corr_Tyc', 'ra_pmdec_corr_Tyc', 'dec_pmdec_corr_Tyc',\n",
       "       'parallax_pmdec_corr_Tyc', 'pmra_pmdec_corr_Tyc', 'HenryDraperId_Tyc',\n",
       "       'name_simbad', 'parallax_simbad', 'radial_vel_simbad', 'Vmag_simbad',\n",
       "       'sptype_simbad', 'ra_simbad', 'dec_simbad', 'pmra_simbad',\n",
       "       'pmdec_simbad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parallax</th>\n",
       "      <th>parallax_simbad</th>\n",
       "      <th>parallax_Hip</th>\n",
       "      <th>parallax_Tyc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.352951</td>\n",
       "      <td>6.35</td>\n",
       "      <td>44.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.957504</td>\n",
       "      <td>9.96</td>\n",
       "      <td>26.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.728640</td>\n",
       "      <td>15.73</td>\n",
       "      <td>-96.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.746190</td>\n",
       "      <td>5.75</td>\n",
       "      <td>30.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.512226</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-8.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.740228</td>\n",
       "      <td>4.74</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.007318</td>\n",
       "      <td>5.01</td>\n",
       "      <td>44.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.694079</td>\n",
       "      <td>7.69</td>\n",
       "      <td>46.83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.734405</td>\n",
       "      <td>2.73</td>\n",
       "      <td>11.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.867527</td>\n",
       "      <td>5.87</td>\n",
       "      <td>-27.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.888071</td>\n",
       "      <td>67.89</td>\n",
       "      <td>389.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.506877</td>\n",
       "      <td>2.51</td>\n",
       "      <td>15.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.161279</td>\n",
       "      <td>5.16</td>\n",
       "      <td>60.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.936046</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.569750</td>\n",
       "      <td>4.57</td>\n",
       "      <td>15.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.148808</td>\n",
       "      <td>6.15</td>\n",
       "      <td>-13.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.930454</td>\n",
       "      <td>8.93</td>\n",
       "      <td>96.87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.278582</td>\n",
       "      <td>6.28</td>\n",
       "      <td>15.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.148667</td>\n",
       "      <td>8.15</td>\n",
       "      <td>-39.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.408145</td>\n",
       "      <td>4.41</td>\n",
       "      <td>9.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.716438</td>\n",
       "      <td>7.72</td>\n",
       "      <td>70.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.569676</td>\n",
       "      <td>6.07</td>\n",
       "      <td>75.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.489064</td>\n",
       "      <td>8.49</td>\n",
       "      <td>28.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.537206</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.504812</td>\n",
       "      <td>5.50</td>\n",
       "      <td>47.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.541918</td>\n",
       "      <td>4.54</td>\n",
       "      <td>3.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.832442</td>\n",
       "      <td>6.83</td>\n",
       "      <td>23.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.298219</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-11.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.970428</td>\n",
       "      <td>5.97</td>\n",
       "      <td>-6.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.721153</td>\n",
       "      <td>7.72</td>\n",
       "      <td>58.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341232</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341233</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341235</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341236</th>\n",
       "      <td>NaN</td>\n",
       "      <td>64.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341237</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341238</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>71.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341248</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341253</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341254</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341257</th>\n",
       "      <td>NaN</td>\n",
       "      <td>198.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2341261 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parallax  parallax_simbad  parallax_Hip  parallax_Tyc\n",
       "0         6.352951             6.35         44.39           NaN\n",
       "1         9.957504             9.96         26.42           NaN\n",
       "2        15.728640            15.73        -96.12           NaN\n",
       "3         5.746190             5.75         30.49           NaN\n",
       "4         1.512226             1.51         -8.65           NaN\n",
       "5         4.740228             4.74         14.99           NaN\n",
       "6         5.007318             5.01         44.89           NaN\n",
       "7         7.694079             7.69         46.83           NaN\n",
       "8         2.734405             2.73         11.98           NaN\n",
       "9         5.867527             5.87        -27.21           NaN\n",
       "10       67.888071            67.89        389.59           NaN\n",
       "11        2.506877             2.51         15.75           NaN\n",
       "12        5.161279             5.16         60.43           NaN\n",
       "13        2.936046             2.94         -2.88           NaN\n",
       "14        4.569750             4.57         15.89           NaN\n",
       "15        6.148808             6.15        -13.60           NaN\n",
       "16        8.930454             8.93         96.87           NaN\n",
       "17        6.278582             6.28         15.46           NaN\n",
       "18        8.148667             8.15        -39.29           NaN\n",
       "19        4.408145             4.41          9.64           NaN\n",
       "20        7.716438             7.72         70.46           NaN\n",
       "21       10.569676             6.07         75.18           NaN\n",
       "22        8.489064             8.49         28.80           NaN\n",
       "23        4.537206             4.54          1.53           NaN\n",
       "24        5.504812             5.50         47.39           NaN\n",
       "25        4.541918             4.54          3.96           NaN\n",
       "26        6.832442             6.83         23.72           NaN\n",
       "27        1.298219             1.30        -11.21           NaN\n",
       "28        5.970428             5.97         -6.95           NaN\n",
       "29        7.721153             7.72         58.90           NaN\n",
       "...            ...              ...           ...           ...\n",
       "2341231        NaN            68.10           NaN           NaN\n",
       "2341232        NaN            21.33           NaN           NaN\n",
       "2341233        NaN             6.78           NaN           NaN\n",
       "2341234        NaN             5.77           NaN           NaN\n",
       "2341235        NaN            -2.00           NaN           NaN\n",
       "2341236        NaN            64.80           NaN           NaN\n",
       "2341237        NaN             4.76           NaN           NaN\n",
       "2341238        NaN            17.04           NaN           NaN\n",
       "2341239        NaN             1.00           NaN           NaN\n",
       "2341240        NaN            24.33           NaN           NaN\n",
       "2341241        NaN            75.41           NaN           NaN\n",
       "2341242        NaN            71.30           NaN           NaN\n",
       "2341243        NaN             4.07           NaN           NaN\n",
       "2341244        NaN             7.46           NaN           NaN\n",
       "2341245        NaN            -1.24           NaN           NaN\n",
       "2341246        NaN            25.16           NaN           NaN\n",
       "2341247        NaN            52.00           NaN           NaN\n",
       "2341248        NaN            13.08           NaN           NaN\n",
       "2341249        NaN             7.68           NaN           NaN\n",
       "2341250        NaN            85.10           NaN           NaN\n",
       "2341251        NaN            14.78           NaN           NaN\n",
       "2341252        NaN            70.00           NaN           NaN\n",
       "2341253        NaN             2.92           NaN           NaN\n",
       "2341254        NaN            22.50           NaN           NaN\n",
       "2341255        NaN            57.76           NaN           NaN\n",
       "2341256        NaN             0.41           NaN           NaN\n",
       "2341257        NaN           198.07           NaN           NaN\n",
       "2341258        NaN            18.60           NaN           NaN\n",
       "2341259        NaN             0.96           NaN           NaN\n",
       "2341260        NaN            -0.17           NaN           NaN\n",
       "\n",
       "[2341261 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database[[\"parallax\",\"parallax_simbad\",\"parallax_Hip\",\"parallax_Tyc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging GAIA with RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging by tycho2_id...\n",
      "Number of matchings for tycho2_id: 210263\n",
      "Merging by hip...\n",
      "Number of matchings for hip: 25925\n",
      "Number of matches: 236188\n"
     ]
    }
   ],
   "source": [
    "cols=[\"tycho2_id\",\"hip\"]\n",
    "rvgaia=pd.DataFrame()\n",
    "for col in cols[::1],cols[::-1]:\n",
    "    print(\"Merging by %s...\"%col[0])\n",
    "    result=pd.merge(left=gaia[gaia[col[0]]!=''],\n",
    "                    right=rv[rv[col[0]]!=''],\n",
    "                    on=col[0])\n",
    "    result=result.drop(\"%s_y\"%col[1],1)\n",
    "    result=result.rename(columns={\"%s_x\"%col[1]:col[1]})\n",
    "    print(\"Number of matchings for %s: %d\"%(col[0],len(result)))\n",
    "    rvgaia=rvgaia.append(result)\n",
    "\n",
    "rvgaia=rvgaia.fillna('NULL')\n",
    "rvgaia.to_csv(RV_DIR+\"RVGaia.csv\",index=False)\n",
    "print(\"Number of matches: %d\"%len(rvgaia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hip', 'tycho2_id', 'ra', 'ra_error', 'dec', 'dec_error', 'parallax',\n",
       "       'parallax_error', 'pmra', 'pmra_error', 'pmdec', 'pmdec_error',\n",
       "       'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr', 'ra_pmdec_corr',\n",
       "       'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
       "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',\n",
       "       'phot_g_mean_flux', 'phot_g_mean_flux_error', 'phot_g_mean_mag', 'l',\n",
       "       'b', 'ecl_lon', 'ecl_lat', 'DEJ2000', 'RAJ2000', 'RV', 'eRV', 'CAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvgaia.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urania\r\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
